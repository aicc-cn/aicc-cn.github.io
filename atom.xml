<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AICC</title>
  
  <subtitle>Artificial Intelligence Chinese Community</subtitle>
  <link href="https://aicc-cn.github.io/atom.xml" rel="self"/>
  
  <link href="https://aicc-cn.github.io/"/>
  <updated>2022-03-30T13:09:27.331Z</updated>
  <id>https://aicc-cn.github.io/</id>
  
  <author>
    <name>AICC</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【十三】背景建模</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-13-cv-image_background/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-13-cv-image_background/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:27.331Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景建模"><a href="#背景建模" class="headerlink" title="背景建模"></a>背景建模</h3><h4 id="相对运动的基本方式"><a href="#相对运动的基本方式" class="headerlink" title="相对运动的基本方式"></a>相对运动的基本方式</h4><blockquote><ul><li>相机静止，目标运劢——背景提取(减除)</li><li>相机运劢，目标静止——光流估计(全局运劢)</li><li>相机和目标均运劢——光流估计</li></ul></blockquote><h4 id="帧差法运动目标检测"><a href="#帧差法运动目标检测" class="headerlink" title="帧差法运动目标检测"></a>帧差法运动目标检测</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123141057.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123141057.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>​    如图可见，由目标运动引起的运动变化区域包括运动目标在前后两帧中的共同位置(图中黑色区域)、在当前帧中新显露出的背景区域和新覆盖的背景区域三部分。</p><h5 id="【数学模型】"><a href="#【数学模型】" class="headerlink" title="【数学模型】"></a>【<strong>数学模型</strong>】</h5><p>$sign(x)&#x3D;\begin{cases}<br>1,&amp;如果I(x， y， t)-I(x, y, t-1)&gt;T \ 0,&amp;如果其他情况<br>\end{cases}$</p><blockquote><ul><li>D(x, y): 帧差</li><li>I(x,y,t): 当前帧(t时刻)图像</li><li>I(x,y,t): 上一帧(t-1时刻)图像</li><li>T: 像素灰度差阈值</li></ul></blockquote><h4 id="混合高斯背景建模"><a href="#混合高斯背景建模" class="headerlink" title="混合高斯背景建模"></a>混合高斯背景建模</h4><h5 id="【高斯背景】"><a href="#【高斯背景】" class="headerlink" title="【高斯背景】"></a>【<strong>高斯背景</strong>】</h5><blockquote><p>像素灰度值随时间变化符合高斯分布.</p><p>$I(x, y) \thicksim N(u, \sigma^2)$</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123143447.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123143447.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>如果$I(x, y, t)-u&gt;3\sigma$ 为<code>前景</code>，否则就是<code>背景</code>。<ul><li>$I(x, y, t)$是当前帧。</li><li>$u$为均值、$\sigma$是方差。</li></ul></li></ul><p>注意：当前帧的灰度值变化落在$3\sigma$间的就是背景，否则就是前景。</p></blockquote><h5 id="【混合高斯模型】"><a href="#【混合高斯模型】" class="headerlink" title="【混合高斯模型】"></a>【<strong>混合高斯模型</strong>】</h5><blockquote><p>任何一种分布函数都可以看做是多个高斯分布的组合.</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123144119.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123144119.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>​    混合高斯背景建模是<code>基于像素样本统计信息的背景表示方法</code>，利用像素在较长时间内大量样本值的概率密度等统计信息(如模式数量、每个模式的均值和标准差)表示背景，然后使用<code>统计差分(如3σ原则)进行目标像素判断</code>，可以对复杂动态背景进行建模，计算量较大。<br>​    在混合高斯背景模型中，认为<code>像素之间的颜色信息互不相关，对各像素点的处理都是相互独立的</code>。对于视频图像中的每一个像素点，其值在序列图像中的变化可看作是不断产生像素值的随机过程，即<code>用高斯分布来描述每个像素点的颜色呈现规律&#123;单模态(单峰)，多模态(多峰)&#125;</code>。</p><p>​    对于多峰高斯分布模型，<code>图像的每一个像素点按不同权值的多个高斯分布的叠加来建模，每种高斯分布对应一个可能产生像素点所呈现颜色的状态，各个高斯分布的权值和分布参数随时间更新</code>。当处理彩色图像时，假定图像像素点R、G、B三色通道相互独立并具有相同的方差。对于随机变量X的观测数据集${x_1,x_2,…,x_N}，x_t&#x3D;(r_t,g_t,b_t)$为t时刻像素的样本，则单个采样点$x_t$其服从的混合高斯分布概率密度函数：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123144742.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123144742.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>​    其中Q为分布模式总数，$N(I,u_q, \sigma_q^2)$为高斯分布，$μ_q$为其均值，$δ_q$为方差，I为三维单位矩阵，$ω_q$为高斯分布的权重。</p></blockquote><h5 id="【混合高斯背景建模步骤】"><a href="#【混合高斯背景建模步骤】" class="headerlink" title="【混合高斯背景建模步骤】"></a>【<strong>混合高斯背景建模步骤</strong>】</h5><blockquote><p>任务：在线计算：$μ_q$，$δ_q$，$ω_q$</p></blockquote><blockquote><ol><li>模型初始化 将采到的第一帧图像的每个象素的灰度值作为均值，再赋以较大的方差。初值Q&#x3D;1, w&#x3D;1.0。</li><li>模型学习 将当前帧的对应点象素的灰度值与已有的Q个高斯模型作比较，若满足$|x_k-u_{q, k}|&lt;2.5\sigma_{q,k}$ ，则按概率密度公式调整第q个高斯模型的参数和权重；否则转入(3)：</li><li>增加&#x2F;替换高斯分量 若不满足条件，且q&lt;Q，则增加一个新分量；若q&#x3D;Q，则替换</li><li>判断背景  $B &#x3D; argmin_b(\sum_{q&#x3D;1}^bw_q&gt;T)$</li><li>判断前景</li></ol></blockquote><h5 id="【混合高斯模型迭代计算原理】"><a href="#【混合高斯模型迭代计算原理】" class="headerlink" title="【混合高斯模型迭代计算原理】"></a>【<strong>混合高斯模型迭代计算原理</strong>】</h5><p><strong>迭代计算：</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123150252.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123150252.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>$M_q(k)$为二值化函数，仅当像素值匹配第q类时取1，其余取0</li><li>类别数值取值不大于5</li></ul></blockquote><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote><ol><li>背景静止时，可以使用基于背景提取的运动估计斱法计算运动目标。</li><li>混合高斯模型可模拟任意概率密度函数，是背景建模的主流方法</li><li>混合高斯模型参数采用迭代方式计算。</li></ol></blockquote><h3 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/1/22 21:09</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : backgroundDemo.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 基于背景提取的运动估计</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载视频</span></span><br><span class="line">cap = cv2.VideoCapture()</span><br><span class="line">cap.<span class="built_in">open</span>(<span class="string">&#x27;768x576.avi&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无法打开视频文件&quot;</span>)</span><br><span class="line"></span><br><span class="line">pBgModel = cv2.createBackgroundSubtractorMOG2()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">labelTargets</span>(<span class="params">img, mask, threshold</span>):</span><br><span class="line">    seg = mask.copy()</span><br><span class="line">    cnts = cv2.findContours(seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> cnts[<span class="number">1</span>]:</span><br><span class="line">        area = cv2.contourArea(i)</span><br><span class="line">        <span class="keyword">if</span> area &lt; threshold:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        rect = cv2.boundingRect(i)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;矩形：X:&#123;&#125; Y:&#123;&#125; 宽：&#123;&#125; 高：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(rect[<span class="number">0</span>], rect[<span class="number">1</span>], rect[<span class="number">2</span>], rect[<span class="number">3</span>]))</span><br><span class="line">        cv2.drawContours(img, [i], -<span class="number">1</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">        cv2.rectangle(img, (rect[<span class="number">0</span>], rect[<span class="number">1</span>]), (rect[<span class="number">0</span>] + rect[<span class="number">2</span>], rect[<span class="number">1</span>] + rect[<span class="number">3</span>]), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">1</span>)</span><br><span class="line">        cv2.putText(img, <span class="built_in">str</span>(count), (rect[<span class="number">0</span>], rect[<span class="number">1</span>]), cv2.FONT_HERSHEY_PLAIN, <span class="number">0.5</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>))</span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    flag, source = cap.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> flag:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    image = cv2.pyrDown(source)</span><br><span class="line"></span><br><span class="line">    fgMask = pBgModel.apply(image)</span><br><span class="line"></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">    morphImage_open = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel, iterations=<span class="number">5</span>)</span><br><span class="line">    mask = fgMask - morphImage_open</span><br><span class="line">    _, Mask = cv2.threshold(mask, <span class="number">30</span>, <span class="number">255</span>, cv2.THRESH_BINARY + cv2.THRESH_OTSU)</span><br><span class="line">    <span class="comment"># Mask = cv2.GaussianBlur(Mask, (5, 5), 0)</span></span><br><span class="line">    targets = labelTargets(image, Mask, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;共检测%s个目标&quot;</span> % targets)</span><br><span class="line">    backGround = pBgModel.getBackgroundImage()</span><br><span class="line">    foreGround = image - backGround</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;source&#x27;</span>, image)</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;background&#x27;</span>, backGround)</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;foreground&#x27;</span>, Mask)</span><br><span class="line">    key = cv2.waitKey(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">if</span> key == <span class="number">27</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/GIF.gif" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/GIF.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">运动估计-背景建模</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【十四】光流估计</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-14-cv-image_LK/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-14-cv-image_LK/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:30.980Z</updated>
    
    <content type="html"><![CDATA[<h3 id="光流估计"><a href="#光流估计" class="headerlink" title="光流估计"></a>光流估计</h3><h4 id="【简介】"><a href="#【简介】" class="headerlink" title="【简介】"></a>【<strong>简介</strong>】</h4><blockquote><p>​    在计算机视觉中，Lucas–Kanade光流算法是一种两帧差分的光流估计算法。它由Bruce D. Lucas 和 Takeo Kanade提出。</p></blockquote><h4 id="【光流的概念】"><a href="#【光流的概念】" class="headerlink" title="【光流的概念】"></a>【<strong>光流的概念</strong>】</h4><blockquote><p>(Optical flow or optic flow)它是一种运动模式，这种运动模式指的是一个物体、表面、边缘在一个视角下由一个观察者（比如眼睛、摄像头等）和背景之间形成的明显移动。</p><p>​    光流技术，如运动检测和图像分割，时间碰撞，运动补偿编码，三维立体视差，都是利用了这种边缘或表面运动的技术。</p><p>​    二维图像的移动相对于观察者而言是三维物体移动的在图像平面的投影。</p><p>​    有序的图像可以估计出二维图像的瞬时图像速率或离散图像转移。</p></blockquote><h4 id="【光流算法】"><a href="#【光流算法】" class="headerlink" title="【光流算法】"></a>【光流算法】</h4><blockquote><p>​    它评估了两幅图像的之间的变形，它的<code>基本假设是体素和图像像素守恒</code>。它假设一个物体的颜色在前后两帧没有巨大而明显的变化。</p><p>​    基于这个思路，我们可以得到图像约束方程。不同的光流算法解决了假定了不同附加条件的光流问题。</p></blockquote><h4 id="【基本模型】"><a href="#【基本模型】" class="headerlink" title="【基本模型】"></a>【基本模型】</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123154113.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123154113.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123160039.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123160039.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>基本思想：虽然$t+1$的时候位置进行了移动，如果我们知道<code>灰度是连续变化</code>的，那么我们就可以通过像素的变化推演当前这个中心点大概移动了多少。</p><p>通过当前位置亮度在$I_x，I_y$以及相邻两帧中灰度的变化值$I_t$，来推演$\delta _x，\delta_y$.</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123154311.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123154311.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p><code>我们在检测物体上建立一个小方格里的所有像素位移相同，建立矩阵方程组，解出u、v两个未知数。</code></p></blockquote><ul><li><p>最优化问题（超定方程求解）</p><p>$min |Au-b|$</p></li><li><p>最小二乘解</p><p>$u&#x3D;(A^TA)^{-1}A^Tb$</p></li></ul><blockquote><ul><li>区域像素只有2个时，就是2元1次方程组求解！</li><li>多个像素，比如3∗3时，则是求上述最小二乘解.</li></ul></blockquote><h4 id="【Lucas–Kanade方法】"><a href="#【Lucas–Kanade方法】" class="headerlink" title="【Lucas–Kanade方法】"></a>【Lucas–Kanade方法】</h4><blockquote><p>​    这个算法是最常见，最流行的。它计算两帧在时间t 到t + δt之间每个每个像素点位置的移动。 由于它是基于图像信号的泰勒级数，这种方法称为差分，这就是对于空间和时间坐标使用偏导数。</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123161352.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123161352.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>可信度判断：矩阵求逆是否能实现？</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123161715.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123161715.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>该表达式是和沿着x和y的梯度是密切相关的，只要其中一个为0时，$A^TA$就不可逆。只要当该区域的像素点比较平滑，矩阵就可逆</li><li>通过求特征值来判断计算可信。<ul><li>两个特征值都远大于0，那么就可逆，否则就不可逆或者很难求逆。</li></ul></li></ul></blockquote><h4 id="【金字塔L-K方法】"><a href="#【金字塔L-K方法】" class="headerlink" title="【金字塔L-K方法】"></a>【金字塔L-K方法】</h4><blockquote><p>针对目标运动很快的情况，用原始的L-K方法就没有办法处理了， 需要采用图像金字塔的方法。把图像从小到大的顺序排列。</p></blockquote><blockquote><p>​    金字塔特征跟踪算法描述如下：首先，光流和仿射变换矩阵在最高一层的图像上计算出；将上一层的计算结果作为初始值传递给下一层图像，这一层的图像在这个初始值的基础上，计算这一层的光流和仿射变化矩阵；再将这一层的光流和仿射矩阵作为初始值传递给下一层图像，直到传递给最后一层，即原始图像层，这一层计算出来的光流和仿射变换矩阵作为最后的光流和仿射变换矩阵的结果。</p></blockquote><ul><li><p>用不同像素的图片建立金字塔</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123185018.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123185018.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>运行L-K方法</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123185057.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123185057.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><blockquote><p>优点：可处理大位移；对噪声更不敏感。</p></blockquote><h4 id="【数学模型】"><a href="#【数学模型】" class="headerlink" title="【数学模型】"></a>【<strong>数学模型</strong>】</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123190149.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190123190149.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote><ol><li>光流估计基于恒定亮度假设模型</li><li>L-K光流估计方法利用了邻域内的运动不变性</li><li>金字塔L-K方法可有效提高光流计算对大位移的鲁棒性</li></ol></blockquote><h3 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/1/22 22:20</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : sightDemo.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 加载视频</span></span><br><span class="line">cap = cv2.VideoCapture()</span><br><span class="line">cap.<span class="built_in">open</span>(<span class="string">&#x27;768x576.avi&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无法打开视频文件&quot;</span>)</span><br><span class="line"></span><br><span class="line">lk_params = <span class="built_in">dict</span>(winSize=(<span class="number">15</span>, <span class="number">15</span>),</span><br><span class="line">                 maxLevel=<span class="number">2</span>,</span><br><span class="line">                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, <span class="number">10</span>, <span class="number">0.03</span>))</span><br><span class="line"></span><br><span class="line">feature_params = <span class="built_in">dict</span>(maxCorners=<span class="number">500</span>,</span><br><span class="line">                      qualityLevel=<span class="number">0.3</span>,</span><br><span class="line">                      minDistance=<span class="number">7</span>,</span><br><span class="line">                      blockSize=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">App</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, video_src</span>):  <span class="comment"># 构造方法，初始化一些参数和视频路径</span></span><br><span class="line">        self.track_len = <span class="number">10</span></span><br><span class="line">        self.detect_interval = <span class="number">5</span></span><br><span class="line">        self.tracks = []</span><br><span class="line">        self.cam = cv2.VideoCapture(video_src)</span><br><span class="line">        self.frame_idx = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):  <span class="comment"># 光流运行方法</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            ret, frame = self.cam.read()  <span class="comment"># 读取视频帧</span></span><br><span class="line">            <span class="keyword">if</span> ret:</span><br><span class="line">                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  <span class="comment"># 转化为灰度虚图像</span></span><br><span class="line">                vis = frame.copy()</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(self.tracks) &gt; <span class="number">0</span>:  <span class="comment"># 检测到角点后进行光流跟踪</span></span><br><span class="line">                    img0, img1 = self.prev_gray, frame_gray</span><br><span class="line">                    p0 = np.float32([tr[-<span class="number">1</span>] <span class="keyword">for</span> tr <span class="keyword">in</span> self.tracks]).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                    p1, st, err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, <span class="literal">None</span>,</span><br><span class="line">                                                           **lk_params)  <span class="comment"># 前一帧的角点和当前帧的图像作为输入来得到角点在当前帧的位置</span></span><br><span class="line">                    p0r, st, err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, <span class="literal">None</span>,</span><br><span class="line">                                                            **lk_params)  <span class="comment"># 当前帧跟踪到的角点及图像和前一帧的图像作为输入来找到前一帧的角点位置</span></span><br><span class="line">                    d = <span class="built_in">abs</span>(p0 - p0r).reshape(-<span class="number">1</span>, <span class="number">2</span>).<span class="built_in">max</span>(-<span class="number">1</span>)  <span class="comment"># 得到角点回溯与前一帧实际角点的位置变化关系</span></span><br><span class="line">                    good = d &lt; <span class="number">1</span>  <span class="comment"># 判断d内的值是否小于1，大于1跟踪被认为是错误的跟踪点</span></span><br><span class="line">                    new_tracks = []</span><br><span class="line">                    <span class="keyword">for</span> tr, (x, y), good_flag <span class="keyword">in</span> <span class="built_in">zip</span>(self.tracks, p1.reshape(-<span class="number">1</span>, <span class="number">2</span>), good):  <span class="comment"># 将跟踪正确的点列入成功跟踪点</span></span><br><span class="line">                        <span class="keyword">if</span> <span class="keyword">not</span> good_flag:</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line">                        tr.append((x, y))</span><br><span class="line">                        <span class="keyword">if</span> <span class="built_in">len</span>(tr) &gt; self.track_len:</span><br><span class="line">                            <span class="keyword">del</span> tr[<span class="number">0</span>]</span><br><span class="line">                        new_tracks.append(tr)</span><br><span class="line">                        cv2.circle(vis, (x, y), <span class="number">2</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">                    self.tracks = new_tracks</span><br><span class="line">                    cv2.polylines(vis, [np.int32(tr) <span class="keyword">for</span> tr <span class="keyword">in</span> self.tracks], <span class="literal">False</span>,</span><br><span class="line">                                  (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>))  <span class="comment"># 以上一振角点为初始点，当前帧跟踪到的点为终点划线</span></span><br><span class="line">                    <span class="comment"># draw_str(vis, (20, 20), &#x27;track count: %d&#x27; % len(self.tracks))</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> self.frame_idx % self.detect_interval == <span class="number">0</span>:  <span class="comment"># 每5帧检测一次特征点</span></span><br><span class="line">                    mask = np.zeros_like(frame_gray)  <span class="comment"># 初始化和视频大小相同的图像</span></span><br><span class="line">                    mask[:] = <span class="number">255</span>  <span class="comment"># 将mask赋值255也就是算全部图像的角点</span></span><br><span class="line">                    <span class="keyword">for</span> x, y <span class="keyword">in</span> [np.int32(tr[-<span class="number">1</span>]) <span class="keyword">for</span> tr <span class="keyword">in</span> self.tracks]:  <span class="comment"># 跟踪的角点画圆</span></span><br><span class="line">                        cv2.circle(mask, (x, y), <span class="number">5</span>, <span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">                    p = cv2.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)  <span class="comment"># 像素级别角点检测</span></span><br><span class="line">                    <span class="keyword">if</span> p <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        <span class="keyword">for</span> x, y <span class="keyword">in</span> np.float32(p).reshape(-<span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">                            self.tracks.append([(x, y)])  <span class="comment"># 将检测到的角点放在待跟踪序列中</span></span><br><span class="line"></span><br><span class="line">                self.frame_idx += <span class="number">1</span></span><br><span class="line">                self.prev_gray = frame_gray</span><br><span class="line">                cv2.imshow(<span class="string">&#x27;lk_track&#x27;</span>, vis)</span><br><span class="line"></span><br><span class="line">            ch = <span class="number">0xFF</span> &amp; cv2.waitKey(<span class="number">100</span>)</span><br><span class="line">            <span class="keyword">if</span> ch == <span class="number">27</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">App(<span class="string">&#x27;768x576.avi&#x27;</span>).run()</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/123.gif" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/123.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">运动估计-光流估计</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【十七】相机标定</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-17-cv-image_calibration/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-17-cv-image_calibration/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:46.623Z</updated>
    
    <content type="html"><![CDATA[<h3 id="相机标定"><a href="#相机标定" class="headerlink" title="相机标定"></a>相机标定</h3><h4 id="【基本问题】"><a href="#【基本问题】" class="headerlink" title="【基本问题】"></a>【基本问题】</h4><ul><li><p><strong>相机内外参数标定</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152254.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152254.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>计算$m_{ij}$的解</li><li>分解内、外参数</li><li>考虑非线性项</li></ul></blockquote></li></ul><h4 id="【Zhang方法】"><a href="#【Zhang方法】" class="headerlink" title="【Zhang方法】"></a>【Zhang方法】</h4><ul><li><p>Zhang方法：由张正友提出，OpenCV等广泛使用</p><blockquote><ul><li>特点：使用平面靶标摆多个pose(可未知)</li><li>标定步骤<ul><li>对一个pose,计算单应矩阵(类似M矩阵)</li><li>有三个以上Pose，根据各单应矩阵计算线性相机参数；</li><li>使用非线性优化方法计算非线性参数</li></ul></li></ul></blockquote></li><li><p>第一步：求解单应矩阵——基本方程</p><ul><li><p>特点：使用平面靶标摆多个pose(可未知)</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152710.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152710.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>平面靶标有四个点或更多时，可求解H(差一比例因子)</p></li></ul></li><li><p>第二步：求解单应矩阵——建立内参数方程</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152857.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152857.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li><p>根据R约束</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152920.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227152920.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>对应每一个pose,可得到上述两个方程</p></li></ul></li><li><p>第三步：求解内参数——建立方程</p><ul><li><p>令 $B&#x3D;(b_{ij})&#x3D;M_1^{-T}M_1^{-1}$</p></li><li><p>根据B对称，定义参数向量</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153140.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153140.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul></li><li><p>第四步：求解参数——建立内参数方程</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153428.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153428.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>第五步：求解参数——内参数求解</p><ul><li><p>当n&gt;&#x3D;3 时,可求解b</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153504.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153504.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>解为：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153528.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153528.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>前式代入，可知：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153547.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153547.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>进一步可确定$M_1$各参数</p></li></ul></li><li><p>第六步：求解参数——外参数求解</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153634.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153634.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li><p>系数</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153717.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153717.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul></li><li><p>最后一步：非线性畸变参数求解</p><ul><li><p>以已有解为初值，求解下式：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153752.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153752.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>可使用Levenberg-Marquardt算法求解(原方法中只含径向畸变)</p></blockquote></li></ul></li></ul><p><strong>外参数标定结果示意</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153933.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153933.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>重投影示意</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153950.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227153950.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="【总结】"><a href="#【总结】" class="headerlink" title="【总结】"></a>【总结】</h4><blockquote><ul><li>Zhang方法从多个角度拍摄平面标定物，进一步通过特征点计算内、外参数及非线性畸变</li><li>与已有方法相比，Zhang方法简单，不需要已知目标特征点三维坐标，因而得到广泛应用</li><li>注意：参与标定的数据一般为30张左右。</li></ul></blockquote><h3 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/2/26 20:15</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : CameraCalibration.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 摄像机标定</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置寻找亚像素角点的参数，采用的停止准则是最大循环次数30和最大误差容限0.001</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span><br><span class="line"><span class="comment"># 准备目标点，例如 (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)</span></span><br><span class="line">objp = np.zeros((<span class="number">6</span> * <span class="number">7</span>, <span class="number">3</span>), np.float32)</span><br><span class="line"><span class="comment"># 将世界坐标系建在标定板上，所有点的Z坐标全部为0，所以只需要赋值x和y</span></span><br><span class="line">objp[:, :<span class="number">2</span>] = np.mgrid[<span class="number">0</span>:<span class="number">7</span>, <span class="number">0</span>:<span class="number">6</span>].T.reshape(-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于存储所有图像中的对象点和图像点的数组。</span></span><br><span class="line">objpoints = []  <span class="comment"># 存储在现实世界空间的3d点</span></span><br><span class="line">imgpoints = []  <span class="comment"># 储存图像平面中的2d点。</span></span><br><span class="line">images = glob.glob(<span class="string">&#x27;image/*.jpg&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> images:</span><br><span class="line">    img = cv2.imread(fname)</span><br><span class="line">    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment"># 获取XY坐标</span></span><br><span class="line">    size = gray.shape[::-<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 找到棋盘角点</span></span><br><span class="line">    ret, corners = cv2.findChessboardCorners(gray, (<span class="number">7</span>, <span class="number">6</span>), <span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># 如果找到，添加3D点，2D点</span></span><br><span class="line">    <span class="keyword">if</span> ret:</span><br><span class="line">        objpoints.append(objp)</span><br><span class="line">        <span class="comment"># 增加角点的准确度</span></span><br><span class="line">        corners2 = cv2.cornerSubPix(gray, corners, (<span class="number">11</span>, <span class="number">11</span>), (-<span class="number">1</span>, -<span class="number">1</span>), criteria)</span><br><span class="line">        imgpoints.append(corners2)</span><br><span class="line">        <span class="comment"># 画出并显示角点</span></span><br><span class="line">        img = cv2.drawChessboardCorners(img, (<span class="number">7</span>, <span class="number">6</span>), corners2, ret)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">        cv2.waitKey(<span class="number">500</span>)</span><br><span class="line"><span class="comment"># 相机标定</span></span><br><span class="line">ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, size, <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 保存相机参数</span></span><br><span class="line">np.savez(<span class="string">&#x27;C.npz&#x27;</span>, mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ret:&quot;</span>, ret)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;内参数矩阵:\n&quot;</span>, mtx)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;畸变系数:\n&quot;</span>, dist)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;旋转向量:&quot;</span>, rvecs)  <span class="comment"># 外参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;平移向量:&quot;</span>, tvecs)  <span class="comment"># 外参数</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190228215354.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190228215354.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">位姿估计-相机标定</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【十五】坐标变换与摄像机模型</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-15-cv-image_camera/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-15-cv-image_camera/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:39.256Z</updated>
    
    <content type="html"><![CDATA[<h3 id="坐标变换与摄像机模型"><a href="#坐标变换与摄像机模型" class="headerlink" title="坐标变换与摄像机模型"></a>坐标变换与摄像机模型</h3><h4 id="图像变换模型"><a href="#图像变换模型" class="headerlink" title="图像变换模型"></a>图像变换模型</h4><h5 id="【平移变换】"><a href="#【平移变换】" class="headerlink" title="【平移变换】"></a>【平移变换】</h5><blockquote><p>只改变图形位置，不改变图形的大小和形状.</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225203846.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225203846.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong><code>代码及演示</code></strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">source_image = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;source&#x27;</span>, source_image)</span><br><span class="line"><span class="comment"># 平移图片</span></span><br><span class="line">rows, cols = source_image.shape</span><br><span class="line"><span class="comment"># 创建交换矩阵，按（100,50）平移</span></span><br><span class="line">M = np.float32([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">100</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">50</span>]])</span><br><span class="line"><span class="comment"># 使用仿射变换的api进行平移变换</span></span><br><span class="line">translation_image = cv2.warpAffine(source_image, M, (cols, rows))</span><br><span class="line">cv2.imshow(<span class="string">&#x27;translation&#x27;</span>, translation_image)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225212105.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225212105.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h5 id="【旋转变换】"><a href="#【旋转变换】" class="headerlink" title="【旋转变换】"></a>【旋转变换】</h5><blockquote><p>将输入图像绕笛卡尔坐标系的原点逆时针旋转$\theta$角度， 则变换后图像坐标为</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225204017.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225204017.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote><p><strong><code>代码及演示</code></strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">source_image = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;source&#x27;</span>, source_image)</span><br><span class="line"><span class="comment"># 获取形状</span></span><br><span class="line">rows, cols = source_image.shape</span><br><span class="line"><span class="comment"># 旋转图片</span></span><br><span class="line"><span class="comment"># 创建交换矩阵， 旋转90度</span></span><br><span class="line">M = cv2.getRotationMatrix2D(((cols-<span class="number">1</span>)/<span class="number">2.</span>, (rows-<span class="number">1</span>)/<span class="number">2.</span>), <span class="number">90</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 使用仿射变换的api进行旋转变换</span></span><br><span class="line">rotation_image = cv2.warpAffine(source_image, M, (cols, rows))</span><br><span class="line">cv2.imshow(<span class="string">&#x27;rotation&#x27;</span>, rotation_image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225212849.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225212849.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h5 id="【比例变换】"><a href="#【比例变换】" class="headerlink" title="【比例变换】"></a>【比例变换】</h5><blockquote><p>若图像坐标$(x, y)$ 缩放到$(S_x, S_y)$倍，则变换函数为：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225204208.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225204208.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>其中$S_y$, 分别为 x和y 坐标的缩放因子，其大于1表示放大，小于1表示缩小。</p></blockquote><p><strong><code>代码及演示</code></strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">source_image = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;source&#x27;</span>, source_image)</span><br><span class="line"><span class="comment"># 获取形状</span></span><br><span class="line">rows, cols = source_image.shape</span><br><span class="line"><span class="comment"># 比例变换</span></span><br><span class="line"><span class="comment"># 缩小一半</span></span><br><span class="line">proportion_image = cv2.resize(source_image, (cols//<span class="number">2</span>, rows//<span class="number">2</span>), cv2.INTER_CUBIC)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;proportion&#x27;</span>, proportion_image)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225213626.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225213626.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h5 id="【仿射变换】"><a href="#【仿射变换】" class="headerlink" title="【仿射变换】"></a>【仿射变换】</h5><blockquote><p>简单的来说就是一个<code>线性变换加上平移</code></p><p>仿射变换的一般表达式为:</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225205543.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225205543.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>平移、比例缩放和旋转变换都是一种称为仿射变换的特殊情况。</p></blockquote><p><strong><code>仿射变换的性质</code></strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227160734.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227160734.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>仿射变换有6个自由度（对应变换中的6个系数），因此，仿射变换后互相平行直线仍然为平行直线，三角形映射后仍是三角形。但却不能保证将四边形以上的多边形映射为等边数的多边形。</li><li>仿射变换，可以保持原来的线共点，点共线的关系不变，保持原来相互平行的的先仍然相互平行，保持原来在一直线上几段线段之间的比例 关系不变。但是，仿射变换不能保持原来的线段长度不变，也不能保持原来的夹角角度不变。</li><li>仿射变换的乘积和逆变换仍是仿射变换。</li><li>仿射变换能够实现平移、旋转、缩放等几何变换。</li></ul></blockquote><p><strong><code>代码及演示</code></strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">source_image = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;source&#x27;</span>, source_image)</span><br><span class="line"><span class="comment"># 获取形状</span></span><br><span class="line">rows, cols = source_image.shape</span><br><span class="line"><span class="comment"># 仿射变换</span></span><br><span class="line"><span class="comment"># 定义交换矩阵</span></span><br><span class="line">pts1 = np.float32([[<span class="number">50</span>, <span class="number">50</span>], [<span class="number">200</span>, <span class="number">50</span>], [<span class="number">50</span>, <span class="number">200</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">10</span>, <span class="number">100</span>], [<span class="number">200</span>, <span class="number">50</span>], [<span class="number">100</span>, <span class="number">250</span>]])</span><br><span class="line">M = cv2.getAffineTransform(pts1, pts2)</span><br><span class="line"><span class="comment"># 开始变换</span></span><br><span class="line">affine_image = cv2.warpAffine(source_image, M, (cols, rows))</span><br><span class="line">plt.subplot(<span class="number">121</span>), plt.imshow(source_image), plt.title(<span class="string">&#x27;Input&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>), plt.imshow(affine_image), plt.title(<span class="string">&#x27;Output&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">cv2.imshow(<span class="string">&#x27;affine&#x27;</span>, affine_image)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225214526.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225214526.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h5 id="【透视变换】"><a href="#【透视变换】" class="headerlink" title="【透视变换】"></a>【透视变换】</h5><blockquote><ul><li>把物体的三维图像表示转变为二维表示的过程，称为透视变换，也称为投影映射，其表达式为:</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225205814.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225205814.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>透视变换也是一种平面映射 ，并且可以保证任意方向上的直线经过透视变换后仍然保持是直线。</li><li>透视变换具有9个自由度（其变换系数为9个），故可以实现平面四边形到四边形的映射。</li></ul></blockquote><p><strong><code>透视变化示意</code></strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225205928.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225205928.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>对于透视投影，一束平行于投影面的平行线的投影可保持平行，而不平行于投影面的平行线的投影会聚集到一个点，该点称<code>灭点</code>.</p></blockquote><p><strong><code>代码及演示</code></strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">source_image = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;source&#x27;</span>, source_image)</span><br><span class="line"><span class="comment"># 获取形状</span></span><br><span class="line">rows, cols = source_image.shape</span><br><span class="line"><span class="comment"># 透视变换</span></span><br><span class="line"><span class="comment"># 定义交换矩阵</span></span><br><span class="line">pts1 = np.float32([[<span class="number">56</span>, <span class="number">65</span>], [<span class="number">368</span>, <span class="number">52</span>], [<span class="number">28</span>, <span class="number">387</span>], [<span class="number">389</span>, <span class="number">390</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">300</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">300</span>], [<span class="number">300</span>, <span class="number">300</span>]])</span><br><span class="line">M = cv2.getPerspectiveTransform(pts1, pts2)</span><br><span class="line"><span class="comment"># 开始变换</span></span><br><span class="line">perspective_image = cv2.warpPerspective(source_image, M, (<span class="number">300</span>, <span class="number">300</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">121</span>), plt.imshow(source_image), plt.title(<span class="string">&#x27;Input&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>), plt.imshow(perspective_image), plt.title(<span class="string">&#x27;Output&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">cv2.imshow(<span class="string">&#x27;perspective&#x27;</span>, proportion_image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225215028.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190225215028.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="坐标系和坐标变换"><a href="#坐标系和坐标变换" class="headerlink" title="坐标系和坐标变换"></a>坐标系和坐标变换</h4><ul><li><p>不同坐标系及坐标变换关系</p><blockquote><p>当物体旋转时，其上的点在固定坐标系坐标值变化。</p></blockquote></li><li><p>任意两个三维坐标系之间的变换关系</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226133821.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226133821.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>注意：R满足旋转矩阵正交性约束</p></blockquote></li><li><p>坐标系变换及旋转矩阵生成示意图</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226134034.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226134034.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><h5 id="【像素坐标系】"><a href="#【像素坐标系】" class="headerlink" title="【像素坐标系】"></a>【像素坐标系】</h5><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185321.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185321.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p><strong>像素坐标系</strong>uov是一个二维直角坐标系，反映了相机CCD&#x2F;CMOS芯片中像素的排列情况。原点o位于图像的左上角，u轴、v轴分别于像面的两边平行。像素坐标系中坐标轴的单位是像素（整数）。</p></blockquote><h5 id="【图像坐标系】"><a href="#【图像坐标系】" class="headerlink" title="【图像坐标系】"></a>【图像坐标系】</h5><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226134217.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226134217.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p><strong>图像坐标系</strong>(x,y)：像素坐标系不利于坐标变换，因此需要建立图像坐标系XOY，其坐标轴的单位通常为毫米（mm），原点是相机光轴与相面的交点（称为主点），即图像的中心点，X轴、Y轴分别与u轴、v轴平行。故两个坐标系实际是平移关系，即可以通过平移就可得到。</p></blockquote><h5 id="【摄像机坐标系】"><a href="#【摄像机坐标系】" class="headerlink" title="【摄像机坐标系】"></a>【摄像机坐标系】</h5><blockquote><p><strong>相机坐标系</strong>（camera coordinate）($O_cX_cY_cZ_c (camera frame)$)，也是一个三维直角坐标系，原点位于镜头光心处，x、y轴分别与相面的两边平行，z轴为镜头光轴，与像平面垂直。</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226134644.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226134644.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h5 id="【世界坐标系】"><a href="#【世界坐标系】" class="headerlink" title="【世界坐标系】"></a>【世界坐标系】</h5><blockquote><p><strong>世界坐标系</strong>（world coordinate）($O_wX_wY_wZ_w$)，也称为测量坐标系，是一个三维直角坐标系，以其为基准可以描述相机和待测物体的空间位置。世界坐标系的位置可以根据实际情况自由确定。</p></blockquote><h5 id="【手端坐标系或平台坐标系】"><a href="#【手端坐标系或平台坐标系】" class="headerlink" title="【手端坐标系或平台坐标系】"></a>【手端坐标系或平台坐标系】</h5><blockquote><p>$O_eX_eY_eZ_e$</p></blockquote><h5 id="【目标坐标系】"><a href="#【目标坐标系】" class="headerlink" title="【目标坐标系】"></a>【目标坐标系】</h5><blockquote><p>$O_tX_tY_tZ_t$</p></blockquote><h5 id="【坐标系转换】"><a href="#【坐标系转换】" class="headerlink" title="【坐标系转换】"></a>【坐标系转换】</h5><ul><li><p><strong>世界坐标系转换为相机坐标系</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160556.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160556.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>其中R为3*3的旋转矩阵，t为3*1的平移矢量，即相机外参数</p></blockquote></li><li><p><strong>相机坐标系转换为图像坐标系</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160628.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160628.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>s为比例因子（s不为0），f为有效焦距（光心到图像平面的距离），(x,y,z,1)是空间点P在相机坐标系oxyz中的齐次坐标，(X,Y,1)是像点p在图像坐标系OXY中的齐次坐标。</p></blockquote></li><li><p><strong>图像坐标系转换为像素坐标系</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160706.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160706.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>其中，dX、dY分别为像素在X、Y轴方向上的物理尺寸，$u_0,v_0$为主点（图像原点）坐标</p></blockquote></li><li><p><strong>世界坐标系转换为像素坐标系</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160855.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226160855.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>其中，$m_1、m_2$即为相机的内参和外参数。</p><p>注意：R,t参数矩阵为不可逆矩阵。</p></blockquote></li></ul><h4 id="线性及非线性摄像机模型"><a href="#线性及非线性摄像机模型" class="headerlink" title="线性及非线性摄像机模型"></a>线性及非线性摄像机模型</h4><h5 id="【线性摄像机模型】"><a href="#【线性摄像机模型】" class="headerlink" title="【线性摄像机模型】"></a>【线性摄像机模型】</h5><ul><li><p>考虑简化的针孔模型</p><blockquote><p>​    针孔模型是各种相机模型中最简单的一种，它是相机的一个近似线性模型。在相机坐标系下，任一点$P(X_c,Y_c,Z_c)$在像平面的投影位置,也就是说，任一点$P(X_c,Y_c,Z_c)$的投影点p(x,y)都是OP（即光心（投影中心）与点$P(X_c,Y_c,Z_c)$的连线）与像平面的交点如下图。</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226184641.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226184641.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140023.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140023.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>加入相机坐标系与世界坐标系变换关系，得到</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140120.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140120.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140311.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140311.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><blockquote><p>说明：上述公式中完成了从<code>世界坐标系</code>到<code>图像坐标系</code>的转变，中间经过了<code>相机坐标系</code>的过度，$X_w$中的w表示world世界，单位为毫米，而u,v是的 单位为像素，即完成了从毫米——像素的转换。</p><p>所以，为了得到空间物体的三维世界坐标，就必须有两个或更多的相机构成立体视觉系统模型才能实现。</p></blockquote><p><strong>成像畸变示意</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140930.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140930.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140938.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226140938.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h5 id="【非线性摄像机模型】"><a href="#【非线性摄像机模型】" class="headerlink" title="【非线性摄像机模型】"></a>【非线性摄像机模型】</h5><blockquote><p>在实际的成像过程中，考虑镜头的失真，一般都存在非线性畸变，所以线性模型不能准确描述成像几何关系。非线性畸可用下列公式描述：</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185028.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185028.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185040.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185040.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li><p>径向畸变，离心畸变，薄棱镜畸变</p><blockquote><p>通常只考虑径向畸变：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551161540304.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551161540304.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li><li><p>若考虑非线性畸变，则对相机标定时需要使用非线性优化算法。而有研究表明引入过多的非线性参入（如离心畸变和薄棱畸变）不仅不能提高精度，还会引起解的不稳定。一般情况下径向畸变就足以描述非线性畸变，所有本课题只是考虑径向畸变。则将式(2.9)中的径向畸变代入式(2.8)可得：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185128.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226185128.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h4><blockquote><ul><li>图像变换包括平秱、旋转、仿射、透视变换等</li><li>常用的坐标系包括像素坐标系、相机坐标系、世界坐标系等，任一点在世界坐标系和相机坐标系中的坐标通过投影矩阵M相关联，M包含了内参数和外参数矩阵</li><li>一般相机成像存在非线性畸变，重点需要考虑径向畸变</li></ul></blockquote>]]></content>
    
    
    <summary type="html">位姿估计-坐标变换与摄像机模型</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【十六】相对位姿测量算法</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-16-cv-image_position/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-16-cv-image_position/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:42.814Z</updated>
    
    <content type="html"><![CDATA[<h3 id="相对位姿测量算法"><a href="#相对位姿测量算法" class="headerlink" title="相对位姿测量算法"></a>相对位姿测量算法</h3><h4 id="【基于空间多点】"><a href="#【基于空间多点】" class="headerlink" title="【基于空间多点】"></a>【基于空间多点】</h4><ul><li><p><strong>相对位姿估计的基本问题</strong></p><blockquote><ul><li>已知：相机内参数；多个空间上的特征点(非共面)在目标坐标系(3D)和相平面坐标系(2D)坐标。</li><li>输出：目标坐标系相对相机坐标系的位置和姿态。</li></ul></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226190648.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226190648.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p><strong>基本思想示意</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226190725.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226190725.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p><strong>线性求解</strong></p><ul><li><p>对每一个特征点，均有：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226191229.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226191229.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>对每一个特征点，均有：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194028.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194028.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>展开第一行</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194052.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194052.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>类似展开第二、第三行：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194126.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194126.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>消去$Z_c$</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194214.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194214.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>上二式右侧分母移到左边，得：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194247.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194247.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>整理为矩阵形式</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194444.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194444.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>对于每一个点都可以形成如上两个方程，对于多个点，可进行堆叠，并记成矩阵形式：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194513.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194513.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>有六个或以上特征点且非共面时，可求解：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194611.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194611.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>上面求出的只有11个参数，且多一个&#x2F;t3. 最后一个变量可利用如下约束求出</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194640.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194640.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>线性求解总结</p><blockquote><p>利用矩阵的QR分解，得到最终的旋转矩阵非奇异矩阵P的正交三角分解：P&#x3D;QR,  其中Q(维数n*s): 正交阵； R :上三角阵</p><p>证明思路：对P 中各向量进行正交化</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194856.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226194856.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li></ul></li></ul><h4 id="【扩展】"><a href="#【扩展】" class="headerlink" title="【扩展】"></a>【扩展】</h4><ul><li><p>根据旋转矩阵计算旋转角</p><blockquote><p>相机坐标系想要转到与世界坐标系完全平行（即坐标轴完全平行，且方向相同），需要旋转3次，设原始相机坐标系为C0<br>1、 C0绕其Z轴旋转，得到新的坐标系C1；<br>2、 C1绕其Y轴旋转，得到新的坐标系C2（注意旋转轴为C1的Y轴，而非C0的Y轴）；<br>3、 C2绕其X轴旋转，得到新的坐标系C3。此时C3与世界坐标系完全平行。</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226220707.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226220707.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li><li><p>Rodrigues旋转</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226220856.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226220856.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>空间的任何一个旋转，可表达为一个向量绕旋转轴旋转给定角度。可用四元数表达：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226221704.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226221704.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226221722.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226221722.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226221732.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190226221732.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><h4 id="【基于平面多特征点】"><a href="#【基于平面多特征点】" class="headerlink" title="【基于平面多特征点】"></a>【基于平面多特征点】</h4><ul><li><p><strong>基本问题</strong></p><blockquote><p>已知：相机内参数；多个平面上的特征点在目标坐标系(3D)和相平面坐标系(2D)坐标。</p><p>输出：目标坐标系相对相机坐标系的位置和姿态。</p></blockquote></li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151524.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151524.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li><p>平面特征点相对位姿估计——线性求解</p><ul><li><p>设$Z_t&#x3D;0$(特征共面), 则对每一个特征点，均有：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151704.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151704.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>得到两个方程</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151740.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151740.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>未知数线性求解</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151810.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151810.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>对于每一个点都可以形成如上两个方程，对于&gt;&#x3D;4个点，可使用类似PnP方法求得解：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151918.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190227151918.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul></li></ul><h4 id="【总结】"><a href="#【总结】" class="headerlink" title="【总结】"></a>【总结】</h4><blockquote><ul><li>在已知至少六个空间点三维点坐标的条件下，可通过点的图像坐标及相对位姿估计算法计算相对位姿。</li><li>在已知至少四个平面点三维点坐标的条件下，可通过点的图像坐标及相对位姿估计算法计算相对位姿。</li></ul></blockquote><h3 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/2/26 21:25</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : PositionMeasurement.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 实现位姿测量算法</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载相机标定的数据</span></span><br><span class="line"><span class="keyword">with</span> np.load(<span class="string">&#x27;C.npz&#x27;</span>) <span class="keyword">as</span> X:</span><br><span class="line">    mtx, dist, _, _ = [X[i] <span class="keyword">for</span> i <span class="keyword">in</span> (<span class="string">&#x27;mtx&#x27;</span>, <span class="string">&#x27;dist&#x27;</span>, <span class="string">&#x27;rvecs&#x27;</span>, <span class="string">&#x27;tvecs&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">img, corners, imgpts</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    在图片上画出三维坐标轴</span></span><br><span class="line"><span class="string">    :param img: 图片原数据</span></span><br><span class="line"><span class="string">    :param corners: 图像平面点坐标点</span></span><br><span class="line"><span class="string">    :param imgpts: 三维点投影到二维图像平面上的坐标</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    corner = <span class="built_in">tuple</span>(corners[<span class="number">0</span>].ravel())</span><br><span class="line">    cv2.line(img, corner, <span class="built_in">tuple</span>(imgpts[<span class="number">0</span>].ravel()), (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">    cv2.line(img, corner, <span class="built_in">tuple</span>(imgpts[<span class="number">1</span>].ravel()), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">    cv2.line(img, corner, <span class="built_in">tuple</span>(imgpts[<span class="number">2</span>].ravel()), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">5</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化目标坐标系的3D点</span></span><br><span class="line">objp = np.zeros((<span class="number">6</span> * <span class="number">7</span>, <span class="number">3</span>), np.float32)</span><br><span class="line">objp[:, :<span class="number">2</span>] = np.mgrid[<span class="number">0</span>:<span class="number">7</span>, <span class="number">0</span>:<span class="number">6</span>].T.reshape(-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 初始化三维坐标系</span></span><br><span class="line">axis = np.float32([[<span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, -<span class="number">3</span>]]).reshape(-<span class="number">1</span>, <span class="number">3</span>)  <span class="comment"># 坐标轴</span></span><br><span class="line"><span class="comment"># 加载打包所有图片数据</span></span><br><span class="line">images = glob.glob(<span class="string">&#x27;image/*.jpg&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> images:</span><br><span class="line">    img = cv2.imread(fname)</span><br><span class="line">    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment"># 找到图像平面点坐标点</span></span><br><span class="line">    ret, corners = cv2.findChessboardCorners(gray, (<span class="number">7</span>, <span class="number">6</span>), <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> ret:</span><br><span class="line">        <span class="comment"># PnP计算得出旋转向量和平移向量</span></span><br><span class="line">        _, rvecs, tvecs, _ = cv2.solvePnPRansac(objp, corners, mtx, dist)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;旋转变量&quot;</span>, rvecs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平移变量&quot;</span>, tvecs)</span><br><span class="line">        <span class="comment"># 计算三维点投影到二维图像平面上的坐标</span></span><br><span class="line">        imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)</span><br><span class="line">        <span class="comment"># 把坐标显示图片上</span></span><br><span class="line">        img = draw(img, corners, imgpts)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">        cv2.waitKey(<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>运行结果</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190228221322.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190228221322.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">位姿估计-相对位姿测量算法</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>基于FAST的特征匹配</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-21-cv-fast_feature/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-21-cv-fast_feature/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:10:01.458Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/3/4 13:57</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : ImageMatching-FAST.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 使用FAST进行提取特征点进行图片匹配</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">imgL = cv2.imread(<span class="string">&#x27;image/A.jpg&#x27;</span>)</span><br><span class="line">imgR = cv2.imread(<span class="string">&#x27;image/B.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)</span><br><span class="line">grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 提取特征点</span></span><br><span class="line">fast = cv2.FastFeatureDetector_create(<span class="number">50</span>)</span><br><span class="line">kL = fast.detect(grayL, <span class="literal">None</span>)</span><br><span class="line">kR = fast.detect(grayR, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 提取描述子</span></span><br><span class="line">br = cv2.BRISK_create()</span><br><span class="line">kL, dL = br.compute(grayL, kL)</span><br><span class="line">kR, dR = br.compute(grayR, kR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 BFMatcher 对象</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L2)</span><br><span class="line"><span class="comment"># 根据描述子匹配特征点.</span></span><br><span class="line">matches = bf.match(dL, dR)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, matches, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;FAST&quot;</span>, img3)</span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 初始化Bruteforce匹配器</span></span><br><span class="line">bf = cv2.BFMatcher()</span><br><span class="line"><span class="comment"># 通过KNN匹配两张图片的描述子</span></span><br><span class="line">matches = bf.knnMatch(dL, dR, k=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 筛选比较好的匹配点</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> i, (m, n) <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.6</span> * n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, good, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;FAST-BF&quot;</span>, img3)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323143205.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323143205.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">FAST特征匹配</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>基于SIFT的特征匹配</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-24-cv-SIFT_feature/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-24-cv-SIFT_feature/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:10:34.128Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/3/2 22:26</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : ImageMatching-SIFT.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 使用SIFT进行提取特征点进行图片匹配</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">imgL = cv2.imread(<span class="string">&#x27;image/A.jpg&#x27;</span>)</span><br><span class="line">imgR = cv2.imread(<span class="string">&#x27;image/B.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)</span><br><span class="line">grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 提取特征点</span></span><br><span class="line">sift = cv2.xfeatures2d_SIFT.create()</span><br><span class="line">kL, dL = sift.detectAndCompute(grayL, <span class="literal">None</span>)</span><br><span class="line">kR, dR = sift.detectAndCompute(grayR, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 BFMatcher 对象</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L2)</span><br><span class="line"><span class="comment"># 根据描述子匹配特征点.</span></span><br><span class="line">matches = bf.match(dL, dR)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, matches, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;SIFT&quot;</span>, img3)</span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 设置FLANN 超参数</span></span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">0</span></span><br><span class="line"><span class="comment"># K-D树索引超参数</span></span><br><span class="line">index_params = <span class="built_in">dict</span>(algorithm=FLANN_INDEX_KDTREE, trees=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 搜索超参数</span></span><br><span class="line">search_params = <span class="built_in">dict</span>(checks=<span class="number">50</span>)</span><br><span class="line"><span class="comment"># 初始化FlannBasedMatcher匹配器</span></span><br><span class="line">flann = cv2.FlannBasedMatcher(index_params, search_params)</span><br><span class="line"><span class="comment"># 通过KNN的方式匹配两张图的描述子</span></span><br><span class="line">matches = flann.knnMatch(dL, dR, k=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 筛选比较好的匹配点</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> i, (m, n) <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.6</span> * n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, good, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;SIFT-FLANN&quot;</span>, img3)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323144134.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323144134.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">SIFT特征匹配</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>基于ORB的特征匹配</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-22-cv-ORB_feature/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-22-cv-ORB_feature/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:10:07.373Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/3/4 12:54</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : ImageMatching-ORB.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 使用ORB进行提取特征点进行图片匹配</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">imgL = cv2.imread(<span class="string">&#x27;image/A.jpg&#x27;</span>)</span><br><span class="line">imgR = cv2.imread(<span class="string">&#x27;image/B.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)</span><br><span class="line">grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 提取特征点</span></span><br><span class="line">orb = cv2.ORB_create()</span><br><span class="line">kL, dL = orb.detectAndCompute(grayL, <span class="literal">None</span>)</span><br><span class="line">kR, dR = orb.detectAndCompute(grayR, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 BFMatcher 对象</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L2)</span><br><span class="line"><span class="comment"># 根据描述子匹配特征点.</span></span><br><span class="line">matches = bf.match(dL, dR)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, matches, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;ORB&quot;</span>, img3)</span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 初始化Bruteforce匹配器</span></span><br><span class="line">bf = cv2.BFMatcher()</span><br><span class="line"><span class="comment"># 通过KNN匹配两张图片的描述子</span></span><br><span class="line">matches = bf.knnMatch(dL, dR, k=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 筛选比较好的匹配点</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> i, (m, n) <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.6</span> * n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, good, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;ORB-BF&quot;</span>, img3)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323143807.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323143807.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">ORB特征匹配</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>基于SURF的特征匹配</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-25-cv-SURF_feature/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-25-cv-SURF_feature/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:10:39.977Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/3/2 21:36</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : ImageMatching-SURF.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 使用SURF进行提取特征点进行图片匹配</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">imgL = cv2.imread(<span class="string">&#x27;image/A.jpg&#x27;</span>)</span><br><span class="line">imgR = cv2.imread(<span class="string">&#x27;image/B.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)</span><br><span class="line">grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 提取特征点</span></span><br><span class="line">surf = cv2.xfeatures2d.SURF_create(hessianThreshold=<span class="number">800</span>)   <span class="comment"># hessian矩阵阈值，在这里调整精度，值越大，点越少，越精准</span></span><br><span class="line">kL, dL = surf.detectAndCompute(grayL, <span class="literal">None</span>)</span><br><span class="line">kR, dR = surf.detectAndCompute(grayR, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 BFMatcher 对象</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L2)</span><br><span class="line"><span class="comment"># 根据描述子匹配特征点.</span></span><br><span class="line">matches = bf.match(dL, dR)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, matches, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;SURF&quot;</span>, img3)</span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 设置FLANN 超参数</span></span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">0</span></span><br><span class="line"><span class="comment"># K-D树索引超参数</span></span><br><span class="line">index_params = <span class="built_in">dict</span>(algorithm=FLANN_INDEX_KDTREE, trees=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 搜索超参数</span></span><br><span class="line">search_params = <span class="built_in">dict</span>(checks=<span class="number">50</span>)</span><br><span class="line"><span class="comment"># 初始化FlannBasedMatcher匹配器</span></span><br><span class="line">flann = cv2.FlannBasedMatcher(index_params, search_params)</span><br><span class="line"><span class="comment"># 通过KNN的方式匹配两张图的描述子</span></span><br><span class="line">matches = flann.knnMatch(dL, dR, k=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 筛选比较好的匹配点</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> i, (m, n) <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.6</span> * n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, good, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;SURF-FLANN&quot;</span>, img3)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323144253.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323144253.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">SURF特征匹配</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【二十】特征匹配</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-20-cv-image_feature/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-20-cv-image_feature/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:58.398Z</updated>
    
    <content type="html"><![CDATA[<h3 id="特征匹配"><a href="#特征匹配" class="headerlink" title="特征匹配"></a>特征匹配</h3><h4 id="【基本问题】"><a href="#【基本问题】" class="headerlink" title="【基本问题】"></a>【基本问题】</h4><ul><li><p>特征点匹配</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302143508.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302143508.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>暴力搜索与2NN判据</p><blockquote><p>设两帧图像中的对应特征点集${𝑥<em>𝑖,𝑦_𝑖}$和${𝑥_𝑖^′,𝑦_𝑖^′}$，共N个特征点 对应点 $𝐱_𝒋&#x3D;(𝑥_𝑗,𝑦_𝑗)$，匹配点为距离最小点 $𝐱_𝑗^′&#x3D;𝑥_𝑗^′∗,𝑦_𝑗^′∗&#x3D;𝑚𝑖𝑛</em>{𝑘&#x3D;1}^𝑁||x_𝑗−𝑥_𝑘^′||$ ，对应距离$𝑑_𝑗^∗$ 进一步得到次小点𝐱′′，对应距离$𝑑_𝑗^{∗′}$, 则匹配点满足：$𝑑_𝑗^∗&lt;𝛼∗𝑑_𝑗^{∗′}$, 认为正常匹配.</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144003.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144003.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li></ul><h4 id="【特征点匹配方法】"><a href="#【特征点匹配方法】" class="headerlink" title="【特征点匹配方法】"></a>【特征点匹配方法】</h4><ul><li><p>快速搜索方式—-二叉树</p><blockquote><ul><li>算法复杂度o(N2)。特征点数量多时，匹配效率低。</li><li>二叉搜索树(BST)提供了高效搜索方式</li><li>以下是一颗一维的二叉搜索树，尝试搜索和11最近的点。</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144354.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144354.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li><li><p>K-D树</p><blockquote><p>对于每一层，可以指定一个划分维度（轴垂直分区面axis-aligned splitting planes）。最简单的就是按照关键字轮流划分（例如：奇数层按照x轴划分，也即第一个关键字；偶数层按照y轴划分，也即第二个关键字）。</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144540.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144540.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li><li><p>K-D树的建立方式</p><blockquote><p>对于所有的样本点，统计它们在每个维上的方差，挑选出方差中的最大值，对应的维就是分裂域的值。数据方差最大表明沿该维度数据点分散得比较开，这个方向上进行数据分割可以获得最好的分辨率；然后再将所有样本点按其第该维的值迕行排序，位于正中间的那个数据点选为分裂结点对应域。重复上述过程直至获得所有叶子节点显示了构建返棵二叉树的所有步骤。</p><p>下面以一个简单的例子来解释上述k-d tree的构建过程。</p><p>假设样本集为：{(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)}。</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144826.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302144826.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li><li><p>K-D树最近邻查询算法</p><blockquote><ol><li>首先通过将查找点数据根结点数据对应维 上的值相比较，按照二叉搜索的方式，顺着“搜索路径”找到最近邻的近似点，也就是 与查询点处于同一个子空间的叶子节点；</li><li>为了防止漏查与查找点 跟进的距离的点，回溯搜索路径，并且判断搜索路径上节点的其他子节点空 间中是否还有距离查询点更近的数据点，如果有，则需要跳到其他子节点空间中去搜索。</li><li>重复返个过程直到搜索路径为空。</li></ol><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302145139.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302145139.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li><li><p>BBF(Best Bin First)</p><blockquote><p>​    BBF的查询思路就是将“查询路径”上的节点进行排序，如按各自分割超平面（称为Bin）与查询点的距离排序,优先考虑距离小的点。BBF还设置了一个运行超时限制，当优先级队列中的所有节点都经过检查或者超出时间限制时，算法返回当前找到的最好结果作为近似的最近邻。</p></blockquote></li><li><p>随机化K-D森林</p><blockquote><p>同时独立建立多个k-d树，每棵树在具有大方差的各维中(如top-5)随机选择。查询时，并行查询多个k-d树，按照BBF准侧将候选节点放在同一队列中。</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302145410.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302145410.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li></ul><h4 id="【RANSAC】"><a href="#【RANSAC】" class="headerlink" title="【RANSAC】"></a>【RANSAC】</h4><ul><li><p>稳健(robust): 对数据噪声的敏感性</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302145622.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302145622.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>基本思想</p><blockquote><p>RANSAC通过反复选择数据中的一组随机子集来达成目标。被选取的子集被假设为局内点，并用下述方法进行验证：</p><ol><li>有一个模型适应于假设的局内点，即所有的未知参数都能从假设的局内点计算得出。 </li><li>用1中得到的模型去测试所有的其它数据，如果某个点适用于估计的模型，认为它也是局内点。 </li><li>如果有足够多的点被归类为假设的局内点，那么估计的模型就足够合理。 </li><li>然后，用所有假设的局内点去重新估计模型，因为它仅仅被初始的假设局内点估计过。 </li><li>最后，通过估计局内点与模型的错误率来评估模型。</li></ol><p>这个过程被重复执行固定的次数，每次产生的模型要么因为局内点太少而被舍弃，要么因为比现有的模型更好而被选用</p></blockquote></li><li><p>SIFT和RANSAC结合</p><blockquote><p>RANSAC算法在SIFT特征筛选中的主要流程：</p><ol><li>从样本集中随机抽选一个RANSAC样本，即4个匹配点对</li><li>根据返4个匹配点对计算变换矩阵M</li><li>根据样本集，变换矩阵M，和误差度量函数计算满足当前变换矩阵的一致集consensus，并返回一致集中元素个数</li><li>根据当前一致集中元素个数判断是否最优(最大)一致集，若是则更新当前最优一致集</li><li>更新当前错误概率p，若p大于允许的最小错误概率则重复(1)至(4)继续迭代，直到当前错误概率p小于最小错误概率</li></ol></blockquote></li><li><p>结果比较：2NN vs 2NN+RANSAC</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302150106.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302150106.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><h4 id="【总结】"><a href="#【总结】" class="headerlink" title="【总结】"></a>【总结】</h4><blockquote><ul><li>特征匹配是立体视觉、全景视觉、由运动到结构的重要环节</li><li>使用基于k-d树的特征匹配方法，能有效提高搜索效率</li><li>RANSAC是一类随机稳健估计方法，可有效滤除误配点</li></ul></blockquote>]]></content>
    
    
    <summary type="html">极线几何与立体视觉-特征匹配</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>基于Harris的特征匹配</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-23-cv-Harris_feature/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-23-cv-Harris_feature/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:10:25.279Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/3/4 14:35</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : ImageMatching-Harris.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 使用Harris进行提取特征点进行图片匹配</span></span><br><span class="line"><span class="comment"># 选择了一种速度、特征点数量和精度都比较好的组合方案：</span></span><br><span class="line"><span class="comment"># FAST角点检测算法+SURF特征描述子+FLANN(Fast Library for Approximate Nearest Neighbors) 匹配算法。</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">imgL = cv2.imread(<span class="string">&#x27;image/A.jpg&#x27;</span>)</span><br><span class="line">imgR = cv2.imread(<span class="string">&#x27;image/B.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)</span><br><span class="line">grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 提取特征点</span></span><br><span class="line">harris = cv2.xfeatures2d_HarrisLaplaceFeatureDetector.create()</span><br><span class="line">kL = harris.detect(grayL, <span class="literal">None</span>)</span><br><span class="line">kR = harris.detect(grayR, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 提取描述子</span></span><br><span class="line">br = cv2.BRISK_create()</span><br><span class="line">kL, dL = br.compute(grayL, kL)</span><br><span class="line">kR, dR = br.compute(grayR, kR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 BFMatcher 对象</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L2)</span><br><span class="line"><span class="comment"># 根据描述子匹配特征点.</span></span><br><span class="line">matches = bf.match(dL, dR)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, matches, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;Harris&quot;</span>, img3)</span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 初始化Bruteforce匹配器</span></span><br><span class="line">bf = cv2.BFMatcher()</span><br><span class="line"><span class="comment"># 通过KNN匹配两张图片的描述子</span></span><br><span class="line">matches = bf.knnMatch(dL, dR, k=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 筛选比较好的匹配点</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> i, (m, n) <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.6</span> * n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line"><span class="comment"># 画出匹配点</span></span><br><span class="line">img3 = cv2.drawMatches(imgL, kL, imgR, kR, good, <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;Harris-BF&quot;</span>, img3)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323143639.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323143639.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">Harris特征匹配</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【十九】立体视觉</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-19-cv-image_Stereo/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-19-cv-image_Stereo/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:54.805Z</updated>
    
    <content type="html"><![CDATA[<h3 id="立体视觉"><a href="#立体视觉" class="headerlink" title="立体视觉"></a>立体视觉</h3><h4 id="【基本概念】"><a href="#【基本概念】" class="headerlink" title="【基本概念】"></a>【基本概念】</h4><ul><li><p>我们在二维视角中，结构和深度是不确定的</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302140557.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302140557.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>立体视觉：第2个照相机可以解决这种歧义性，通过三角化实现深度测量</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301202859.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301202859.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><h4 id="【平行双目视觉】"><a href="#【平行双目视觉】" class="headerlink" title="【平行双目视觉】"></a>【平行双目视觉】</h4><ul><li><p>假设双目完全平行</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302140858.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302140858.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>空间点三维座标位置求解</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302161109.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302161109.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>视差和深度成反比关系: $z_1 &#x3D; \frac{bf_x}{u_1-u_2}$</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302141519.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302141519.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>空间点三维座标位置求解：一般情况</p><blockquote><ul><li>二摄像机坐标系与世界坐标系位姿关系已知</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302141616.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302141616.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>共4个方程，三个未知数，可求解坐标</li></ul></blockquote></li></ul><h4 id="【三维重构】"><a href="#【三维重构】" class="headerlink" title="【三维重构】"></a>【三维重构】</h4><ul><li><p>三维重构步骤</p><blockquote><ol><li>提取特征点，建立特征匹配</li><li>计算视差</li><li>计算世界坐标</li><li>三角剖分</li><li>三维重构</li></ol></blockquote></li><li><p>提取特征点并建立匹配</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142133.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142133.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>特征匹配方式</p><blockquote><ul><li>特征点提取+特征匹配</li><li>光流匹配</li><li>块匹配</li><li>立体矫正+平行匹配</li></ul></blockquote></li><li><p>视差计算</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142321.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142321.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>计算世界坐标–形成点云数据</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142340.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142340.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>三角剖分：采用经典的Delauney算法</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142431.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142431.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>Delauney算法示意：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142536.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142536.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Delaunay三角网是唯一的（任意四点不能共圆），在Delaunay三角形网中任一三角形的外接圆范围内不会有其它点存在。</p></blockquote></li><li><p>三维重构：基于计算坐标，采用OpenGL绘制三角片</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142640.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190302142640.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>效果不好的主要原因，是图像中深度变化较大，同时灰度变换，而特征点选取的比较稀疏.</p></blockquote></li></ul><h4 id="【总结】"><a href="#【总结】" class="headerlink" title="【总结】"></a>【总结】</h4><blockquote><ul><li>立体视觉可计算空间点的三维坐标。基线越长，距离越近，精度越高</li><li>根据双目视觉进行三维重构包括特征点提取、匹配、坐标计算、三角剖分、三维重构等几个步骤</li></ul></blockquote>]]></content>
    
    
    <summary type="html">极线几何与立体视觉-立体视觉</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>图片拼接</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-26-cv-IMAGE_JOIN/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-26-cv-IMAGE_JOIN/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:10:46.324Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/2/16 21:29</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : ImageJoin.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 图片拼接</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_stitched_image</span>(<span class="params">img1, img2, M</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用关键点来缝合图像</span></span><br><span class="line"><span class="string">    :param img1:</span></span><br><span class="line"><span class="string">    :param img2:</span></span><br><span class="line"><span class="string">    :param M: 对应矩阵</span></span><br><span class="line"><span class="string">    :return: 拼接后的图片数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 获取输入图片的维度</span></span><br><span class="line">    w1, h1 = img1.shape[:<span class="number">2</span>]</span><br><span class="line">    w2, h2 = img2.shape[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成对应维度的画布</span></span><br><span class="line">    img1_dims = np.float32([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, w1], [h1, w1], [h1, <span class="number">0</span>]]).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    img2_dims_temp = np.float32([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, w2], [h2, w2], [h2, <span class="number">0</span>]]).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取透视变换的交换矩阵</span></span><br><span class="line">    img2_dims = cv2.perspectiveTransform(img2_dims_temp, M)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 最终的维度</span></span><br><span class="line">    result_dims = np.concatenate((img1_dims, img2_dims), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始拼接图片</span></span><br><span class="line">    <span class="comment"># 通过匹配点来计算维度</span></span><br><span class="line">    [x_min, y_min] = np.int32(result_dims.<span class="built_in">min</span>(axis=<span class="number">0</span>).ravel() - <span class="number">0.5</span>)</span><br><span class="line">    [x_max, y_max] = np.int32(result_dims.<span class="built_in">max</span>(axis=<span class="number">0</span>).ravel() + <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 变换后创建输出矩阵</span></span><br><span class="line">    transform_dist = [-x_min, -y_min]</span><br><span class="line">    transform_array = np.array([[<span class="number">1</span>, <span class="number">0</span>, transform_dist[<span class="number">0</span>]],</span><br><span class="line">                                [<span class="number">0</span>, <span class="number">1</span>, transform_dist[<span class="number">1</span>]],</span><br><span class="line">                                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 修正图像以获得结果图像</span></span><br><span class="line">    result_img = cv2.warpPerspective(img2, transform_array.dot(M),</span><br><span class="line">                                     (x_max - x_min, y_max - y_min))</span><br><span class="line">    result_img[transform_dist[<span class="number">1</span>]:w1 + transform_dist[<span class="number">1</span>], transform_dist[<span class="number">0</span>]:h1 + transform_dist[<span class="number">0</span>]] = img1</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回最终结果</span></span><br><span class="line">    <span class="keyword">return</span> result_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_sift_homography</span>(<span class="params">img1, img2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用SIFT方法获取两张图片的关键点</span></span><br><span class="line"><span class="string">    :param img1:</span></span><br><span class="line"><span class="string">    :param img2:</span></span><br><span class="line"><span class="string">    :return: 关键点组成的对应矩阵</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 初始化SIFT方法</span></span><br><span class="line">    sift = cv2.xfeatures2d_SIFT.create()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取关键点和描述子</span></span><br><span class="line">    k1, d1 = sift.detectAndCompute(img1, <span class="literal">None</span>)</span><br><span class="line">    k2, d2 = sift.detectAndCompute(img2, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化Bruteforce匹配器</span></span><br><span class="line">    bf = cv2.BFMatcher()</span><br><span class="line">    <span class="comment"># 通过KNN匹配两张图片的描述子</span></span><br><span class="line">    matches = bf.knnMatch(d1, d2, k=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 确定最好的匹配</span></span><br><span class="line">    verified_matches = []</span><br><span class="line">    <span class="keyword">for</span> m1, m2 <span class="keyword">in</span> matches:</span><br><span class="line">        <span class="comment"># 把匹配的较好的添加到矩阵中</span></span><br><span class="line">        <span class="keyword">if</span> m1.distance &lt; <span class="number">0.8</span> * m2.distance:</span><br><span class="line">            verified_matches.append(m1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 最小匹配数</span></span><br><span class="line">    min_matches = <span class="number">8</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(verified_matches) &gt; min_matches:</span><br><span class="line">        <span class="comment"># 存储匹配点</span></span><br><span class="line">        img1_pts = []</span><br><span class="line">        img2_pts = []</span><br><span class="line">        <span class="comment"># 将匹配点加入矩阵中</span></span><br><span class="line">        <span class="keyword">for</span> match <span class="keyword">in</span> verified_matches:</span><br><span class="line">            img1_pts.append(k1[match.queryIdx].pt)</span><br><span class="line">            img2_pts.append(k2[match.trainIdx].pt)</span><br><span class="line">        img1_pts = np.float32(img1_pts).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        img2_pts = np.float32(img2_pts).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 计算单应矩阵</span></span><br><span class="line">        M, mask = cv2.findHomography(img1_pts, img2_pts, cv2.RANSAC, <span class="number">5.0</span>)</span><br><span class="line">        <span class="keyword">return</span> M</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Error: Not enough matches&#x27;</span>)</span><br><span class="line">        exit()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">changeImage</span>(<span class="params">img1, img2</span>):</span><br><span class="line">    <span class="comment"># 使用SIFT查找关键点并返回关键点组成的矩阵</span></span><br><span class="line">    M = get_sift_homography(img1, img2)</span><br><span class="line">    <span class="comment"># 使用关键点矩阵将图像缝合在一起</span></span><br><span class="line">    result_image = get_stitched_image(img2, img1, M)</span><br><span class="line">    <span class="keyword">return</span> result_image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 加载图片</span></span><br><span class="line">    img1 = cv2.imread(<span class="string">&quot;images/csdn_A.jpg&quot;</span>)</span><br><span class="line">    img2 = cv2.imread(<span class="string">&quot;images/csdn_B.jpg&quot;</span>)</span><br><span class="line">    img3 = cv2.imread(<span class="string">&quot;images/csdn_C.jpg&quot;</span>)</span><br><span class="line">    <span class="comment"># 显示加载的图片</span></span><br><span class="line">    input_images = np.hstack((img1, img2, img3))</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;Input Images&#x27;</span>, input_images)</span><br><span class="line"></span><br><span class="line">    out1 = changeImage(img1, img2)</span><br><span class="line">    out2 = changeImage(img1, img3)</span><br><span class="line">    result_image = changeImage(out1, out2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存文件</span></span><br><span class="line">    result_image_name = <span class="string">&#x27;results/result_tree.jpg&#x27;</span></span><br><span class="line">    cv2.imwrite(result_image_name, result_image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示拼接的结果</span></span><br><span class="line">    cv2.imshow(<span class="string">&#x27;Result&#x27;</span>, result_image)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323145021.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323145021.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">图片拼接</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【十八】极线几何</title>
    <link href="https://aicc-cn.github.io/2019/03/23/2019-03-18-cv-image_PolarGeometry/"/>
    <id>https://aicc-cn.github.io/2019/03/23/2019-03-18-cv-image_PolarGeometry/</id>
    <published>2019-03-22T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:51.554Z</updated>
    
    <content type="html"><![CDATA[<h3 id="极线几何"><a href="#极线几何" class="headerlink" title="极线几何"></a>极线几何</h3><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301202859.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301202859.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>有时候我们使用一个相机进行拍摄目标物体的时候，会 发现几个物体都重合了，但是当我们再放台相机的时候，就可以把这些物体的特征获取到。</p><p>也就是双目视觉对应关系，同时也可用于相邻两帧间的运动估计。</p></blockquote><h4 id="【基本概念】"><a href="#【基本概念】" class="headerlink" title="【基本概念】"></a>【基本概念】</h4><blockquote><p>极线几何(Epipolar geometry)</p><ul><li>(匹配)极线约束：匹配点必须在极线上</li><li>基线：左右像机光心连线</li><li>极平面：空间点，两像机光心决定的平面</li><li>极点：基线与两摄像机图像平面的交点</li><li>极线：极平面与图片平面的交线</li></ul></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301203308.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301203308.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="【本质矩阵】"><a href="#【本质矩阵】" class="headerlink" title="【本质矩阵】"></a>【本质矩阵】</h4><blockquote><p><strong>本质矩阵</strong> <strong>E</strong>（Essential Matrix）：反映【<strong>空间一点</strong> <strong>P</strong> <strong>的像点】</strong>在【<strong>不同视角摄像机】</strong>下【<strong>摄像机坐标系】</strong>中的表示之间的关系。</p></blockquote><ul><li><p>前面我们已经知道了各个坐标系之前的转换</p><ul><li>相机坐标系与世界坐标系</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301204745.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301204745.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>相机坐标系与图像坐标系</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551444580057.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551444580057.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>两相机坐标系某点与对应图像坐标系的关系：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301205229.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301205229.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>同一点在两相机坐标系之间的关系：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301205312.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301205312.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>两边同时叉积$t$：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301205438.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301205438.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>再与$p_r^\sim​$点积：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551445425466.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551445425466.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><h4 id="【本质矩阵求解】"><a href="#【本质矩阵求解】" class="headerlink" title="【本质矩阵求解】"></a>【本质矩阵求解】</h4><ul><li><p>基本方程</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210555.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210555.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>线性方程求解</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210713.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210713.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>有九个点(非共面)时，可获得线性解：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210826.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210826.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>注意：解与真实解相差一个比例系数</p></blockquote></li><li><p>使用SVD分解求解平移和旋转矩阵</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210911.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210911.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210925.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301210925.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>可以证明，本质矩阵有2个相同的非零特征值</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551446959523.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/1551446959523.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301212931.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301212931.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>因此，最终可以得到4个解，但仅有一个合理解</p></blockquote></li></ul><h4 id="【扩展】"><a href="#【扩展】" class="headerlink" title="【扩展】"></a>【扩展】</h4><blockquote><p><strong>基本矩阵(Fundamental matrix)<strong>： 反映【</strong>空间一点</strong> <strong>P</strong> <strong>的像素点】</strong>在【<strong>不同视角摄像机】</strong>下【<strong>图像坐标系</strong>】中的表示之间的关系。</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301213256.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190301213256.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>两个对应点在像素座标系的对应关系(包含相机内参数信息)</p></blockquote><h4 id="【总结】"><a href="#【总结】" class="headerlink" title="【总结】"></a>【总结】</h4><blockquote><ul><li>极线是极平面和像平面交线，极点是极线和基线交点</li><li>本质矩阵确定了两帧图像中对应点的约束关系</li><li>可以通过8个对应点求解本质矩阵，进一步分解得到R和t</li></ul></blockquote><h3 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/3/1 22:03</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : PolarGeometry.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 极线几何，测量极线</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">img1 = cv2.imread(<span class="string">&#x27;image/l.jpg&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">img2 = cv2.imread(<span class="string">&#x27;image/r.jpg&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化SIFT方法</span></span><br><span class="line">sift = cv2.xfeatures2d_SIFT.create()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取关键点和描述子</span></span><br><span class="line">k1, d1 = sift.detectAndCompute(img1, <span class="literal">None</span>)</span><br><span class="line">k2, d2 = sift.detectAndCompute(img2, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置FLANN 超参数</span></span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">0</span></span><br><span class="line"><span class="comment"># K-D树索引超参数</span></span><br><span class="line">index_params = <span class="built_in">dict</span>(algorithm=FLANN_INDEX_KDTREE, trees=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 搜索超参数</span></span><br><span class="line">search_params = <span class="built_in">dict</span>(checks=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化FlannBasedMatcher匹配器</span></span><br><span class="line">flann = cv2.FlannBasedMatcher(index_params, search_params)</span><br><span class="line"><span class="comment"># 通过KNN的方式匹配两张图的描述子</span></span><br><span class="line">matches = flann.knnMatch(d1, d2, k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">good = []</span><br><span class="line">pts1 = []</span><br><span class="line">pts2 = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选比较好的匹配点</span></span><br><span class="line"><span class="keyword">for</span> i, (m, n) <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.8</span> * n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line">        pts2.append(k2[m.trainIdx].pt)</span><br><span class="line">        pts1.append(k1[m.queryIdx].pt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算基础矩阵</span></span><br><span class="line">pts1 = np.int32(pts1)</span><br><span class="line">pts2 = np.int32(pts2)</span><br><span class="line"><span class="comment"># F为基本矩阵、mask是返回基本矩阵的值：没有找到矩阵，返回0，找到一个矩阵返回1，多个矩阵返回3</span></span><br><span class="line">F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_LMEDS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只选择有效数据</span></span><br><span class="line">pts1 = pts1[mask.ravel() == <span class="number">1</span>]</span><br><span class="line">pts2 = pts2[mask.ravel() == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drawlines</span>(<span class="params">img1, img2, lines, pts1, pts2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制图像极线</span></span><br><span class="line"><span class="string">    :param img1:</span></span><br><span class="line"><span class="string">    :param img2:</span></span><br><span class="line"><span class="string">    :param lines:</span></span><br><span class="line"><span class="string">    :param pts1:</span></span><br><span class="line"><span class="string">    :param pts2:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    r, c = img1.shape</span><br><span class="line">    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)</span><br><span class="line">    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> r, pt1, pt2 <span class="keyword">in</span> <span class="built_in">zip</span>(lines, pts1, pts2):</span><br><span class="line">        color = <span class="built_in">tuple</span>(np.random.randint(<span class="number">0</span>, <span class="number">255</span>, <span class="number">3</span>).tolist())</span><br><span class="line">        x0, y0 = <span class="built_in">map</span>(<span class="built_in">int</span>, [<span class="number">0</span>, -r[<span class="number">2</span>] / r[<span class="number">1</span>]])</span><br><span class="line">        x1, y1 = <span class="built_in">map</span>(<span class="built_in">int</span>, [c, -(r[<span class="number">2</span>] + r[<span class="number">0</span>] * c) / r[<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, <span class="number">1</span>)</span><br><span class="line">        img1 = cv2.circle(img1, <span class="built_in">tuple</span>(pt1), <span class="number">5</span>, color, -<span class="number">1</span>)</span><br><span class="line">        img2 = cv2.circle(img2, <span class="built_in">tuple</span>(pt2), <span class="number">5</span>, color, -<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> img1, img2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在右图（第二图）中找到与点相对应的极线，并在左图上画出它的线。</span></span><br><span class="line">lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>), <span class="number">2</span>, F)</span><br><span class="line">lines1 = lines1.reshape(-<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">img5, img6 = drawlines(img1, img2, lines1, pts1, pts2)</span><br><span class="line"><span class="comment"># 找到与左图像（第一个图像）中的点对应的极线，以及在右图上画线</span></span><br><span class="line">lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>), <span class="number">1</span>, F)</span><br><span class="line">lines2 = lines2.reshape(-<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">img3, img4 = drawlines(img2, img1, lines2, pts2, pts1)</span><br><span class="line">plt.subplot(<span class="number">121</span>), plt.imshow(img5)</span><br><span class="line">plt.subplot(<span class="number">122</span>), plt.imshow(img3)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323142108.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190323142108.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">极线几何与立体视觉-极线几何</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【一】计算机视觉引论</title>
    <link href="https://aicc-cn.github.io/2019/03/22/2019-03-01-cv-introduction/"/>
    <id>https://aicc-cn.github.io/2019/03/22/2019-03-01-cv-introduction/</id>
    <published>2019-03-21T16:00:00.000Z</published>
    <updated>2022-03-30T13:08:47.668Z</updated>
    
    <content type="html"><![CDATA[<h3 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h3><blockquote><p>计算机视觉就是让计算机<code>看懂</code>图像和视频。</p></blockquote><ul><li><p>视觉是自然智能不可思议的结晶</p><blockquote><ul><li>猕猴的大脑皮层中视觉部分占据大约50%</li><li>人脑中有关视觉的部分所占比重最大</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309200421.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309200421.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote></li><li><p>人类大脑对视觉进行层次化的处理</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309200455.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309200455.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>人类采用神经网络对视觉信息进行深层次处理，和深度学习密切结合。</p></blockquote></li></ul><h3 id="计算机视觉的产生和发展都经历的阶段"><a href="#计算机视觉的产生和发展都经历的阶段" class="headerlink" title="计算机视觉的产生和发展都经历的阶段"></a>计算机视觉的产生和发展都经历的阶段</h3><blockquote><ul><li>起源：20世纪50年代统计模式识别，二维图像分析。</li><li>诞生：1974年 Minsky -&gt; David Marr 暑期， 1981年，人工智能“计算机视觉”专辑，Marr视觉计算理论 得到了迅速的发展。</li><li>发展：</li><li>80年代以后：<ul><li>随着计算能力的迅速增长，视觉计算成本极大降低。</li><li>以Marr理论为基础的视觉理论广泛研究。</li></ul></li><li>2000年后，特征提取和基于学习的视觉得到迅速发展。</li><li>2006年，Hinton 提出深度学习。</li><li>2010年， 微软使用深度学习在语音方面取得突破进展。</li><li>2015年后，深度学习在视觉个各邻域取得突破：<ul><li>2015年， 在imageNet上的识别准确率首次超越人类。</li><li>2016年，Tesla 创造了56亿公里的自动驾驶路测数据。</li><li>2017年，iPone x 宣布引入Face ID 高精度人脸识别技术。</li><li>2018年，OpenAI 2:1 战胜人类DOTA2高手队。</li></ul></li></ul></blockquote><h3 id="计算机视觉的应用"><a href="#计算机视觉的应用" class="headerlink" title="计算机视觉的应用"></a>计算机视觉的应用</h3><blockquote><ul><li>服务机器人</li><li>安防监控</li><li>自动驾驶</li><li>智能穿戴</li><li>无人机快递</li><li>等等</li></ul></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309200616.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309200616.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="内容架构"><a href="#内容架构" class="headerlink" title="内容架构"></a>内容架构</h3><blockquote><p>遵循Marr视觉计算机理论</p><p>从初略图（2维）–&gt; $2 \frac12$维 –&gt;3维</p><p>初略图</p><ul><li>“看见”–照相，颜色，图像采集的过程。</li><li>“基本理解”– 滤波、边缘检测、灰度直方图、直线检测–基本特征提取</li><li>图像阈值分割、区域生长、图像描述</li><li>关键点及特征检测</li><li>背景建模及运动估计</li></ul><p>$2 \frac12$维</p><ul><li>视觉成像模型、视觉几何基础、相机标定</li></ul><p>3维</p><ul><li>图像拼接</li><li>立体视觉</li></ul><p>从底层–&gt;中层–&gt;高层</p><p>底层是由高等数学，线性代数，矩阵分析，概率论，最优化方法，物理(运动学)来进行架构 作为理论支撑。</p><p>中层：机器视觉是建立在数字图像处理和模式识别之上的。</p><p>高层：深度学习+计算机视觉</p></blockquote><h3 id="即将更新"><a href="#即将更新" class="headerlink" title="即将更新"></a>即将更新</h3><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322201253.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322201253.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">计算机视觉引论</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【二】视觉系统</title>
    <link href="https://aicc-cn.github.io/2019/03/22/2019-03-02-cv-visualsystem/"/>
    <id>https://aicc-cn.github.io/2019/03/22/2019-03-02-cv-visualsystem/</id>
    <published>2019-03-21T16:00:00.000Z</published>
    <updated>2022-03-30T13:08:51.380Z</updated>
    
    <content type="html"><![CDATA[<h3 id="视觉系统构成要素"><a href="#视觉系统构成要素" class="headerlink" title="视觉系统构成要素"></a>视觉系统构成要素</h3><blockquote><ul><li>照明设备：光源</li><li>成像设备：相机</li><li>处理设备：主机</li><li>算法软件：视觉处理系统</li></ul></blockquote><h4 id="【要素的关系】"><a href="#【要素的关系】" class="headerlink" title="【要素的关系】"></a>【要素的关系】</h4><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-9/95153635.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-9/95153635.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="视觉系统构成要素"></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309201004.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309201004.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309201017.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309201017.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="【要素的理解】"><a href="#【要素的理解】" class="headerlink" title="【要素的理解】"></a>【要素的理解】</h4><blockquote><ul><li>光源：对场景进行照明，使能捕捉的范围更大，事物更清晰，一般就是各种光。</li><li>相机：抓取图片，保留信息，一般是指照相机，摄像机，一个或多个。</li><li>主机：处理图片信息，一般为台式计算机或嵌入式处理器。</li><li>算法软件：辅助主机处理图片信息，提取所需要的特征， 一般为C++或者其他编程语言编写的视觉识别算法及程序。</li></ul></blockquote><h4 id="【要素案例】"><a href="#【要素案例】" class="headerlink" title="【要素案例】"></a>【要素案例】</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322201130.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322201130.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>光源：室内光线或专用照明</li><li>相机：放在机械臂前端，单相机</li><li>主机：台式计算机或嵌入式处理器</li><li>算法软件：使用C++或其它语言编写的视觉识别算法及程序</li></ul></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309201230.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309201230.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>光源：红外和可见光</li><li>相机：RGB+红外</li><li>主机：类PC结构</li><li>软件：运行在SoC+后端主机软件</li></ul></blockquote><h3 id="Marr视觉计算机理论"><a href="#Marr视觉计算机理论" class="headerlink" title="Marr视觉计算机理论"></a>Marr视觉计算机理论</h3><blockquote><ul><li>目的：通过视觉系统，重构三维物体的形状和位置</li><li>初略图（2维）：过零点（zero-crossing）、短线段、端点等基本特征</li><li>$2 \frac12$维：对物体形状的一些初略描述</li><li>3维：对物体的三维描述</li></ul></blockquote><h4 id="【解释】"><a href="#【解释】" class="headerlink" title="【解释】"></a>【解释】</h4><blockquote><p>Marr视觉计算机理论就是通过视觉捕捉物体的图像和位置，然后通过技术重构物体的三维特征；这个过程包括：</p><ul><li>先通过图像提取出一些2维的初略图</li><li>然后对物体的形状的特征(法向量等)抽取并做一些初略的描述确定$2 \frac12$维图</li><li>最后综合所有特征形成物体的三维特征图。</li></ul></blockquote>]]></content>
    
    
    <summary type="html">视觉系统</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【三】数字成像系统</title>
    <link href="https://aicc-cn.github.io/2019/03/22/2019-03-03-cv-digitaltoimage/"/>
    <id>https://aicc-cn.github.io/2019/03/22/2019-03-03-cv-digitaltoimage/</id>
    <published>2019-03-21T16:00:00.000Z</published>
    <updated>2022-03-30T13:08:54.599Z</updated>
    
    <content type="html"><![CDATA[<h3 id="光通量"><a href="#光通量" class="headerlink" title="光通量"></a>光通量</h3><blockquote><p>指人眼所能感觉到的辐射功率，它等于单位时间内某一波段的辐射能量和该波段的相对视见率的乘积。</p><p>符号：Φ</p><p>单位：lm(流明)</p><p>1lm &#x3D; 0.00146瓦</p></blockquote><h4 id="常见光源的光通量"><a href="#常见光源的光通量" class="headerlink" title="常见光源的光通量"></a>常见光源的光通量</h4><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/66671052.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/66671052.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="光通量"></p><h3 id="辐照度"><a href="#辐照度" class="headerlink" title="辐照度"></a>辐照度</h3><blockquote><p>指投射到一平方米表面上的辐射通量密度。也就是说是到达一平方米表面上，单位时间，单位面积上的辐射能。</p><p>符号：E</p><p>单位：lux(勒克斯)</p><p>1 lux &#x3D; 1 lm&#x2F;$m^2$</p></blockquote><h4 id="常见照明环境的辐照度"><a href="#常见照明环境的辐照度" class="headerlink" title="常见照明环境的辐照度"></a>常见照明环境的辐照度</h4><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/6673147.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/6673147.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="辐射度"></p><h3 id="光源类别"><a href="#光源类别" class="headerlink" title="光源类别"></a>光源类别</h3><blockquote><p>按方向</p><ul><li>直射光</li><li>漫射光</li></ul><p>按光谱</p><ul><li>可见光</li><li>近可见光</li></ul><p>其他</p><ul><li>偏振</li><li>其他</li></ul></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202114.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202114.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>【<strong>透视轮廓–背光源</strong>】</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202131.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202131.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>发射面是一个漫射面， 均匀性好。可用于镜面反射材料，如晶片或者玻璃基底上的伤痕检测；LCD检测；微小电子元件尺寸、形状、靶标测试</p></blockquote><p>【<strong>表面照明–漫射光源</strong>】</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202143.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202143.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>在一定工作距离下，光束集中、亮度高、均匀性好、照射面积相对较小。常用于液晶校正、塑胶容器检查、工作螺孔定位、标签检查、管脚检查、集成电路印字检查等等</p></blockquote><p>【<strong>颜色光源</strong>】</p><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/88508873.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/88508873.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="互补光源"></p><blockquote><p>如果希望更加鲜明地突出某些颜色，则选择色环上相对应的互补颜色光源照明，这样就可以明显的提高图像的对比度。</p></blockquote><h3 id="RGB"><a href="#RGB" class="headerlink" title="RGB"></a>RGB</h3><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/81330727.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/81330727.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="rgb"></p><blockquote><p>为生活中所最常见的三基色，也是和视觉感受一一致的，很多颜色都是由这三基色产生。</p><p>三基色: 红、绿、蓝</p><p>三色相交互是白色。</p></blockquote><h3 id="CYMK"><a href="#CYMK" class="headerlink" title="CYMK"></a>CYMK</h3><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/84796285.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/84796285.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="cymk"></p><blockquote><p>补色模型</p><p>基色变为基本三基色的补色–红色–&gt;青色、绿色–&gt;黄色、蓝色–&gt;品红</p><p>三基色：青、黄、品红</p><p>三色交互是黑色。</p></blockquote><h3 id="HSI"><a href="#HSI" class="headerlink" title="HSI"></a>HSI</h3><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/29068085.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/29068085.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="hsi"></p><blockquote><ul><li>色调H：描述纯色的属性（红、黄）。</li><li>饱和度S：表示的是一种纯色被白光稀释的程度的度量。</li><li>亮度I：体现了无色的光照强度的概念，是一个主观的描述。</li></ul></blockquote><p>【与RGB<strong>的换算关系</strong>】</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202246.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202246.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><code>代码演示</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;2.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 缩放+灰度化</span></span><br><span class="line">sizeImage = cv2.pyrDown(img)</span><br><span class="line">grayImage = cv2.cvtColor(sizeImage, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&quot;source image&quot;</span>, sizeImage)</span><br><span class="line">cv2.imshow(<span class="string">&quot;gray&quot;</span>, grayImage)</span><br><span class="line"><span class="comment"># RGB通道分离--opencv中，RGB三个通道是反过来的</span></span><br><span class="line">rgbImage = cv2.split(sizeImage)</span><br><span class="line">cv2.imshow(<span class="string">&quot;R&quot;</span>, rgbImage[<span class="number">2</span>])</span><br><span class="line">cv2.imshow(<span class="string">&quot;G&quot;</span>, rgbImage[<span class="number">1</span>])</span><br><span class="line">cv2.imshow(<span class="string">&quot;B&quot;</span>, rgbImage[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 分离后为单通道，相当于分离通道的同时把其他两个通道填充了相同的数值。</span></span><br><span class="line"><span class="comment"># 比如红色通道，分离出红色通道的同时，绿色和蓝色被填充为和红色相同的数值，这样一来就只有黑白灰了。</span></span><br><span class="line"><span class="comment"># 可以进行观察，会发现原图中颜色越接近红色的地方在红色通道越接近白色。</span></span><br><span class="line"><span class="comment"># 在纯红的地方在红色通道会出现纯白。</span></span><br><span class="line"><span class="comment"># R值为255 -&gt; RGB(255，255，255)，为纯白</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HSI颜色模型+通道分离</span></span><br><span class="line">hsv = cv2.cvtColor(sizeImage, cv2.COLOR_BGR2HSV)</span><br><span class="line">hsvChannels = cv2.split(hsv)</span><br><span class="line">cv2.imshow(<span class="string">&quot;Hue&quot;</span>, hsvChannels[<span class="number">0</span>])</span><br><span class="line">cv2.imshow(<span class="string">&quot;Saturation&quot;</span>, hsvChannels[<span class="number">1</span>])</span><br><span class="line">cv2.imshow(<span class="string">&quot;Value&quot;</span>, hsvChannels[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309210844.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309210844.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="CCD传感器基本原理"><a href="#CCD传感器基本原理" class="headerlink" title="CCD传感器基本原理"></a>CCD传感器基本原理</h3><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202350.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202350.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="彩色图像传感器的基本原理"><a href="#彩色图像传感器的基本原理" class="headerlink" title="彩色图像传感器的基本原理"></a>彩色图像传感器的基本原理</h3><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/45875188.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/45875188.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="彩色  图像传感器"></p><blockquote><p>最底层的感光区同样是采用CCD图像传感器</p><p>彩色滤色片阵列(Color Filter Array),也被称为拜尔滤色镜(Bayer Filter)，排列在感光区上方。</p><p>传感器不同，排列方式就不同。</p></blockquote><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/152560.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/152560.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="Bayer"></p><blockquote><p>这个单元包含了三原色：红(R),绿(G),蓝(B)。对于单个像素点，只有一种特定的彩色滤色片放置在其上方。彩色图像的像素点不仅包含通常的感光区域还包括了一个彩色滤色片。因为人眼对绿色的敏感度很高，所以我们使用了更多的绿色滤色片，类似棋盘格的形式来摆放绿色滤色片，以期得到有着更高空间分辨率的图像。红色和蓝色滤色片每隔一行与绿色滤色片错落放置。</p></blockquote><h3 id="γ校正"><a href="#γ校正" class="headerlink" title="γ校正"></a>γ校正</h3><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/21721761.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/21721761.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="校正"></p><blockquote><p>图像传感器输出时经过γ校正，以符合人的视觉习惯；存储时还原回原有的RGB值。</p></blockquote><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/22073630.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/22073630.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="校正环节"></p><h3 id="图像传输的方式"><a href="#图像传输的方式" class="headerlink" title="图像传输的方式"></a>图像传输的方式</h3><blockquote><ul><li>模拟视频传输：采用同轴电缆等方式，将亮度和色度分离，在不同频带调制后在同一信号线上传输。常用的为同轴电缆，同轴电缆的中心导线用于传输信号，外层是金属屏蔽网。</li><li>RGB方式：显示器，投影</li><li>数字传输（长距离）：光纤高清信号，网线</li><li>数字传输（短距离）：USB，火线，HDMI</li></ul></blockquote><h3 id="模拟、数字视频传输接口"><a href="#模拟、数字视频传输接口" class="headerlink" title="模拟、数字视频传输接口"></a>模拟、数字视频传输接口</h3><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202521.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202521.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="常见的图像和视频压缩标准"><a href="#常见的图像和视频压缩标准" class="headerlink" title="常见的图像和视频压缩标准"></a>常见的图像和视频压缩标准</h3><p><img src="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/87798349.jpg" class="lazyload" data-srcset="http://eveseven.oss-cn-shanghai.aliyuncs.com/19-1-11/87798349.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="标准"></p><h3 id="显示设备及参数（液晶显示）"><a href="#显示设备及参数（液晶显示）" class="headerlink" title="显示设备及参数（液晶显示）"></a>显示设备及参数（液晶显示）</h3><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202658.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190309202658.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>分辨率（最佳分辨率）及显示器尺寸</li><li>亮度和对比度：LCD的亮度以流明&#x2F;平方米（cd&#x2F;m2）度量，对比度是直接反映LCD显示器能否现丰富的色阶的参数</li><li>响应时间：响应时间是LCD显示器的一个重要的参数，它指的是LCD显示器对于输入信号的反应时间。</li><li>坏点：如果液晶显示屏中某一个发光单元有问题就会出现总丌透光、总透光、半透光等现象，这就是所谓的“坏点”</li></ul></blockquote>]]></content>
    
    
    <summary type="html">数字成像系统</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【四】图像滤波</title>
    <link href="https://aicc-cn.github.io/2019/03/22/2019-03-04-cv-image_filter/"/>
    <id>https://aicc-cn.github.io/2019/03/22/2019-03-04-cv-image_filter/</id>
    <published>2019-03-21T16:00:00.000Z</published>
    <updated>2022-03-30T13:08:57.681Z</updated>
    
    <content type="html"><![CDATA[<h3 id="图像滤波基本原理"><a href="#图像滤波基本原理" class="headerlink" title="图像滤波基本原理"></a>图像滤波基本原理</h3><blockquote><p>图像信息在采集过程中往往受到各种噪声源的干扰，这些噪声在图像上的常常表现为一些孤立像素点，这可理解为像素的灰度是空间相关的，即噪声点像素灰度与它们临近像素的灰度有着显著不同。通常，一般的前置图像处理后的信息仍然带有后续所不希望夹带的孤立像素点，这种干扰或孤立像素点如不经过滤波处理，会对以后的图像区域分割、分析和判断带来影响。</p></blockquote><h3 id="基本图像预处理滤波方法"><a href="#基本图像预处理滤波方法" class="headerlink" title="基本图像预处理滤波方法"></a>基本图像预处理滤波方法</h3><h4 id="图像滤波与卷积"><a href="#图像滤波与卷积" class="headerlink" title="图像滤波与卷积"></a><strong>图像滤波与卷积</strong></h4><h5 id="【公式定义】"><a href="#【公式定义】" class="headerlink" title="【公式定义】"></a>【<strong>公式定义</strong>】</h5><blockquote><p>与1维信号滤波类似，图像滤波由卷积定义。</p></blockquote><p><img src="https://s2.ax1x.com/2019/01/13/FvLb6O.png" class="lazyload" data-srcset="https://s2.ax1x.com/2019/01/13/FvLb6O.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="卷积公式"></p><blockquote><p>在图像中， 以模板形式定义。</p></blockquote><p><img src="https://s2.ax1x.com/2019/01/13/FvLX0H.png" class="lazyload" data-srcset="https://s2.ax1x.com/2019/01/13/FvLX0H.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="卷积公式模板"></p><blockquote><p>注意：如果滤波器是对称的，那么两个公式就是等价的。</p><p>​        $f(x, y)$为图片原始数据、$g(x, y)$为卷积核。</p></blockquote><h5 id="【计算方式】"><a href="#【计算方式】" class="headerlink" title="【计算方式】"></a>【<strong>计算方式</strong>】</h5><p><strong>举个栗子</strong>：</p><p>假设一张图像有 5x5 个像素，1 代表白，0 代表黑，这幅图像被视为 5x5 的单色图像。现在用一个由随机地 0 和 1 组成的 3x3 矩阵去和图像中的子区域做Hadamard乘积，每次迭代移动一个像素，这样该乘法会得到一个新的 3x3 的矩阵。下面的动图展示了这个过程。 </p><p><img src="https://sevenold.github.io/images/dl/69.gif" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/69.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><p><strong>直观上来理解</strong>：</p><ul><li>用一个小的权重矩阵去覆盖输入数据，对应位置元素加权相乘，其和作为结果的一个像素点。</li><li>这个权重在输入数据上滑动，形成一张新的矩阵</li><li>这个权重矩阵就被称为<code>卷积核</code>（convolution kernel）</li><li>其覆盖的位置称为<code>感受野</code>（receptive fileld ）</li><li>生成的新矩阵叫做<code>特征图</code>（feature map）</li></ul><p>分解开来，就如下图所示：</p><p><img src="https://sevenold.github.io/images/dl/72.png" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/72.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><p><strong>其中：</strong></p><ul><li><p>滑动的像素数量就叫做<code>步长</code>（stride），步长为1，表示跳过1个像素，步长为2，就表示跳过2个像素，以此类推</p><p><img src="https://sevenold.github.io/images/dl/76.gif" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/76.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p></li><li><p>以卷积核的边还是中心点作为开始&#x2F;结束的依据，决定了卷积的<code>补齐</code>（padding）方式。前面我们所举的栗子是<code>valid</code>方式，而<code>same</code>方式则会在图像的边缘用0补齐，如将前面的<code>valid</code>改为<code>same</code>方式，如图所示：</p></li></ul><p><img src="https://sevenold.github.io/images/dl/73.png" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/73.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><p>其采样方式对应变换为：</p><p><img src="https://sevenold.github.io/images/dl/77.gif" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/77.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><ul><li>我们前面所提到的输入图像都是灰色的，只有一个通道，但是我们一般会遇到输入通道不只有一个，那么卷积核是三阶的，也就是说所有的通道的结果做累加。</li></ul><p><img src="https://sevenold.github.io/images/dl/74.png" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/74.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><p><img src="https://sevenold.github.io/images/dl/78.gif" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/78.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><p><img src="https://sevenold.github.io/images/dl/79.gif" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/79.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><p>当然，最后，这里有一个术语：“<code>偏置</code>（bias）”，每个输出滤波器都有一个偏置项，偏置被添加到输出通道产生最终输出通道。 </p><p><img src="https://sevenold.github.io/images/dl/80.gif" class="lazyload" data-srcset="https://sevenold.github.io/images/dl/80.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="images"></p><h4 id="图像去噪"><a href="#图像去噪" class="headerlink" title="图像去噪"></a><strong>图像去噪</strong></h4><h5 id="【平均滤波】"><a href="#【平均滤波】" class="headerlink" title="【平均滤波】"></a>【<strong>平均滤波</strong>】</h5><blockquote><p>在一个小区域内（通常是3*3）像素值平均。</p></blockquote><p><strong>数学公式定义</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113205514.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113205514.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="平均滤波公式"></p><blockquote><p>说明：如果在3*3的一个区域内，如果存在5个有效像素值，那么整体就除以5，以此类推。</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113205855.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113205855.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="平均滤波示例"></p><h5 id="【加权平均滤波】"><a href="#【加权平均滤波】" class="headerlink" title="【加权平均滤波】"></a>【<strong>加权平均滤波</strong>】</h5><blockquote><p>在一个小区域内（通常是3*3）像素值加权平均。</p></blockquote><p><strong>数学公式定义</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113210305.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113210305.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="滤波加权平均"></p><blockquote><p>在进行基本平均滤波前，先把原始数据乘以一个指定的权重值，然后再进行平均。</p></blockquote><p><strong>普通卷积核</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113211941.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113211941.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="普通卷积核"></p><p><strong>高斯卷积核</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113212008.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113212008.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="高斯卷积核"></p><blockquote><p>权重的分布符合高斯分布，所以叫高斯卷积核。</p></blockquote><h5 id="【中值滤波】"><a href="#【中值滤波】" class="headerlink" title="【中值滤波】"></a>【<strong>中值滤波</strong>】</h5><blockquote><ol><li>将滤波模板（含有若干个点的滑动窗口）在图像中漫游，并将模板中心与图中某个像素位置重合</li><li>读取模板中各对应像素的灰度值；</li><li>将这些灰度值从小到大排列；</li><li>取这一列数据的中间数据，将其赋给对应模板中心位置的像素。如果窗口中有奇数个元素，中值取元素按灰度值大小排序后的中间元素灰度值。如果窗口中有偶数个元素，中值取元素按灰度值大小排序后，中间两个元素灰度的平均值。因为图像为二维信号，中值滤波的窗口形状和尺寸对滤波器效果影响很大，不同图像内容和不同应用要求往往选用不同的窗口形状和尺寸。</li></ol></blockquote><p><strong>示例</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113212631.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113212631.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="中值滤波示例"></p><p><strong>常用选取形式</strong></p><p><code>3*3</code></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113213612.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113213612.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="中值滤波选取形式"></p><p><code>5*5</code></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113213654.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113213654.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="中值滤波选取形式"></p><blockquote><p>中值滤波对椒盐噪声有效。</p></blockquote><h3 id="数学形态学滤波"><a href="#数学形态学滤波" class="headerlink" title="数学形态学滤波"></a>数学形态学滤波</h3><h4 id="【概述】"><a href="#【概述】" class="headerlink" title="【概述】"></a>【<strong>概述</strong>】</h4><blockquote><p>形态学（morphology）一词通常表示生物学的一个分支，该分支主要研究动植物的形态和结构。而我们图像处理中指的形态学，往往表示的是数学形态学。</p><p>数学形态学（Mathematical morphology） 是一门建立在格论和拓扑学基础之上的图像分析学科，是数学形态学图像处理的基本理论。其基本的运算包括：二值腐蚀和膨胀、二值开闭运算、骨架抽取、极限腐蚀、击中击不中变换、形态学梯度、Top-hat变换、颗粒分析、流域变换、灰值腐蚀和膨胀、灰值开闭运算、灰值形态学梯度等。</p></blockquote><h4 id="【膨胀和腐蚀】"><a href="#【膨胀和腐蚀】" class="headerlink" title="【膨胀和腐蚀】"></a>【<strong>膨胀和腐蚀</strong>】</h4><blockquote><p>按数学方面来说，膨胀或者腐蚀操作就是将图像（或图像的一部分区域，我们称之为A）与核（我们称之为B）进行卷积。</p><p>核可以是任何的形状和大小，它拥有一个单独定义出来的参考点，我们称其为锚点（anchorpoint）。多数情况下，核是一个小的中间带有参考点和实心正方形或者圆盘，其实，我们可以把核视为模板或者掩码。</p></blockquote><h5 id="膨胀"><a href="#膨胀" class="headerlink" title="膨胀"></a><code>膨胀</code></h5><blockquote><p>膨胀就是求局部最大值的操作，核B与图形卷积，即计算核B覆盖的区域的像素点的最大值，并把这个最大值赋值给参考点指定的像素。这样就会使图像中的高亮区域逐渐增长。</p></blockquote><p><strong>数学定义</strong></p><blockquote><p>$A\oplus B$表示集合A用<code>结构元素B</code>膨胀。</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113214217.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113214217.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="膨胀公式"></p><p><strong>示例</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113221916.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113221916.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="膨胀示例"></p><h5 id="腐蚀"><a href="#腐蚀" class="headerlink" title="腐蚀"></a><code>腐蚀</code></h5><blockquote><p><code>腐蚀</code>就是<code>膨胀</code>的相反操作，腐蚀就是求局部最小值的操作。</p></blockquote><p><strong>数学定义</strong></p><blockquote><p>$A\ominus B$表示集合A用<code>结构元素B</code>腐蚀。</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113215646.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113215646.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="腐蚀数学定义"></p><p><strong>示例</strong></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113222014.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113222014.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="腐蚀结果"></p><h4 id="【开闭运算】"><a href="#【开闭运算】" class="headerlink" title="【开闭运算】"></a>【<strong>开闭运算</strong>】</h4><blockquote><p><code>膨胀</code>和<code>腐蚀</code>并不互为<code>逆运算</code>，二者<code>级联</code>使用可生成新的形态学运算。</p></blockquote><p><code>开运算</code></p><blockquote><p>先腐蚀后膨胀</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113220210.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113220210.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="开运算"></p><p><code>闭运算</code></p><blockquote><p>先膨胀后腐蚀</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113220258.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113220258.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="闭运算"></p><p><code>先开后闭</code></p><blockquote><p>可有效的去除噪声。</p></blockquote><h3 id="滤波总结"><a href="#滤波总结" class="headerlink" title="滤波总结"></a>滤波总结</h3><blockquote><ol><li>滤波即卷积，由逐点乘积后累加得到</li><li>平滑滤波包括平均滤波、高斯滤波、中值滤波等方法，其中高斯滤波最为常用</li><li>数学形态学滤波基于腐蚀与膨胀两个基本操作</li></ol></blockquote><h3 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a><strong>代码演示</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">image = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>)</span><br><span class="line">img = cv2.pyrDown(image)</span><br><span class="line">cv2.imshow(<span class="string">&quot;source image&quot;</span>, img)</span><br><span class="line"><span class="comment"># 高斯平滑滤波</span></span><br><span class="line">gaussImage = cv2.GaussianBlur(img, (<span class="number">5</span>, <span class="number">5</span>), <span class="number">0</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;gauss image&quot;</span>, gaussImage)</span><br><span class="line"><span class="comment"># 中值滤波</span></span><br><span class="line">medianImage = cv2.medianBlur(img, <span class="number">5</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;median image&quot;</span>, medianImage)</span><br><span class="line"><span class="comment"># 形态学滤波</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 腐蚀图像</span></span><br><span class="line">eroded = cv2.erode(img, kernel)</span><br><span class="line">cv2.imshow(<span class="string">&quot;Eroded Image&quot;</span>, eroded)</span><br><span class="line"><span class="comment"># 膨胀图像</span></span><br><span class="line">dilated = cv2.dilate(img, kernel)</span><br><span class="line">cv2.imshow(<span class="string">&quot;dilated Image&quot;</span>, dilated)</span><br><span class="line"><span class="comment"># 形态学滤波-开运算</span></span><br><span class="line">morphImage_open = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)</span><br><span class="line">cv2.imshow(<span class="string">&quot;image-open&quot;</span>, morphImage_open)</span><br><span class="line"><span class="comment"># 形态学滤波-闭运算</span></span><br><span class="line">morphImage_close = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)</span><br><span class="line">cv2.imshow(<span class="string">&quot;image-close&quot;</span>, morphImage_close)</span><br><span class="line"><span class="comment"># 形态学滤波-先开后闭运算</span></span><br><span class="line">morphImage_open_close = cv2.morphologyEx(morphImage_open, cv2.MORPH_CLOSE, kernel)</span><br><span class="line">cv2.imshow(<span class="string">&quot;image-open-close&quot;</span>, morphImage_open_close)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113221555.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190113221555.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="代码演示"></p>]]></content>
    
    
    <summary type="html">视觉处理算法-图像滤波</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【五】图像边缘检测</title>
    <link href="https://aicc-cn.github.io/2019/03/22/2019-03-05-cv-image_edge/"/>
    <id>https://aicc-cn.github.io/2019/03/22/2019-03-05-cv-image_edge/</id>
    <published>2019-03-21T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:00.994Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h3><blockquote><p>边缘检测的基本思想是通过检测每个像素和其邻域的状态，以决定该像素是否位于一个物体的边界上。如果一个像素位于一个物体的边界上，则其邻域像素的灰度值的变化就比较大。假如可以应用某种算法检测出这种变化并进行量化表示，那么就可以确定物体的边界。</p><ul><li>边缘检测的实质是微分。</li><li>实际中常用差分， X方向、Y方向。</li></ul></blockquote><h3 id="基本算子"><a href="#基本算子" class="headerlink" title="基本算子"></a>基本算子</h3><h4 id="【Robert算子：一阶微分算子】"><a href="#【Robert算子：一阶微分算子】" class="headerlink" title="【Robert算子：一阶微分算子】"></a>【<strong>Robert算子：一阶微分算子</strong>】</h4><p>对于图像来说，是一个二维的离散型数集，通过推广二维连续型求函数偏导的方法，来求得图像的偏导数，即在(x,y)处的最大变化率，也就是这里的梯度：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114161922.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114161922.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="robert算子梯度公式"></p><p>梯度是一个矢量，则(x,y)处的梯度表示为：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162158.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162158.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="梯度公式"></p><p>其大小为：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162250.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162250.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="梯度公式"></p><p>因为平方和平方根需要大量的计算开销，所以使用绝对值来近似梯度幅值：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162454.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162454.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="梯度简化计算"></p><p>方向与α(x,y)正交：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162526.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162526.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="正交"></p><p>其对应的模板为：</p><blockquote><p>图像的垂直和水平梯度</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162619.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162619.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>我们有时候也需要对角线方向的梯度，定义如下：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162732.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162732.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="梯度"></p><p>对应模板为：</p><blockquote><p>Roberts 交叉梯度算子。</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162815.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114162815.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="Robert算子"></p><p>模板推导</p><p><code>垂直或水平算子模板</code></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114165059.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114165059.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="垂直或水平模板"></p><p><code>交叉算子模板</code></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114164252.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114164252.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="算子模板推导"></p><blockquote><p>2*2 大小的模板在概念上很简单，但是他们对于用关于中心点对称的模板来计算边缘方向不是很有用，其最小模板大小为3*3。3*3 模板考虑了中心点对段数据的性质，并携带有关于边缘方向的更多信息。</p></blockquote><h4 id="【Prewitt算子：一阶微分算子】"><a href="#【Prewitt算子：一阶微分算子】" class="headerlink" title="【Prewitt算子：一阶微分算子】"></a>【<strong>Prewitt算子：一阶微分算子</strong>】</h4><blockquote><p>prewitt算子一般使用的是3*3的模板</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114165808.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114165808.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="prewitt"></p><p>我如下定义水平、垂直和两对角线方向的梯度:</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114165914.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114165914.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="prewitt梯度"></p><p>Prewitt算子：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114170149.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114170149.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="Prewitt算子"></p><p>数学推导：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114170225.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114170225.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="数学推导prewitt"></p><blockquote><p>Prewitt 算子是由两部分组成，检测水平边缘的模板和检测垂直边缘的模板， Prewitt 算子一个方向求微分，一个方向求平均，所以对噪声相对不敏感。</p></blockquote><h4 id="【Sobel算子：一阶微分算子】"><a href="#【Sobel算子：一阶微分算子】" class="headerlink" title="【Sobel算子：一阶微分算子】"></a>【<strong>Sobel算子：一阶微分算子</strong>】</h4><blockquote><p>Sobel 算子是在Prewitt算子的基础上改进的， 在中心系数上使用一个权值2， 相比较Prewitt算子，Sobel模板能够较好的抑制(平滑)噪声。</p></blockquote><p>计算公式：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114175731.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114175731.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="sobel 算子"></p><p>sobel算子：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114175830.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114175830.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="sobel算子"></p><p>数学推导：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114180216.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114180216.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="sobel数学推"></p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190122203820.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190122203820.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>sobel算子也有两个，一个是检测水平边缘的模板基于sobel算子的边缘检测，另一个是检测垂直边缘的模板基于sobel算子的边缘检测。</li><li>与Prewitt算子相比，sobel算子对于像素位置的影响做了加权，因此效果更好。</li><li>sobel算子的另外一种形式是各向同性Sobel算子， 也有两个模板组成，一个是检测水平边缘的基于sobel算子的边缘检测，另一个是检测垂直边缘的基于sobel算子的边缘检测。</li><li>各向同性Sobel算子和普通sobel算子相比，位置加权系数更为准确，在检测不同方向的边缘是梯度的幅度是一致的。</li></ul></blockquote><h4 id="【Laplace算子：二阶微分算子】"><a href="#【Laplace算子：二阶微分算子】" class="headerlink" title="【Laplace算子：二阶微分算子】"></a>【<strong>Laplace算子：二阶微分算子</strong>】</h4><blockquote><p>Laplace 算子是一种各向同性算子，在只关心边缘的位置而不考虑其周围的像素灰度差值时比较合适。Laplace算子对孤立像素的响应要比对边缘或线的响应要更强烈， 因此只适合用于<code>无噪声图像</code>。存在噪声情况下， 使用Laplace算子检测边缘之前需要先进行<code>低通滤波</code>。</p></blockquote><p>一阶导数：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181441.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181441.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="一阶导数"></p><p>二阶导数：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181509.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181509.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="二阶导数"></p><p>我们需要注意的是关于点x的二阶导数，故将上式中的变量减去1后，得到：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181750.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181750.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="二阶导"></p><p>在图像处理中通过拉普拉斯模板求二阶导数， 其定义如下：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181852.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114181852.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="laplace"></p><p>写成差分形式为</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182154.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182154.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="差分"></p><p>laplace卷积核：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182254.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182254.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="卷积核"></p><p>在用lapacian 算子图像进行卷积运算时，当响应的绝对值超过指定阈值时，那么该点就是被检测出来的孤立点，具体输出如下：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182512.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182512.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="孤立点"></p><h4 id="【LoG算子：二阶微分算子】"><a href="#【LoG算子：二阶微分算子】" class="headerlink" title="【LoG算子：二阶微分算子】"></a>【<strong>LoG算子：二阶微分算子</strong>】</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182657.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182657.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="log算子"></p><blockquote><p>Log 边缘检测则是先进行高斯滤波再进行拉普拉斯算子检测, 然后找过零点来确定边缘位置，很多时候我们只是知道Log 5*5 模板如上图所示。</p></blockquote><p>二维高斯公式：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182751.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182751.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="二维高斯公式"></p><p>按拉普拉斯算子公式求X，Y方向的二阶偏导后：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182855.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114182855.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="二阶偏导"></p><p>这里x，y 不能看成模板位置，应看成是模板其他位置到中心位置的距离。那么写成：</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114183026.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114183026.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="1"></p><p>这里x0，y0 就是模板中心位置，x，y 是模板其他位置，对于5*5 模板， 则$x_0,&#x3D;2 , y_0&#x3D;2$，那对于模板中（0,0）位置的权值，即把x&#x3D; 0，y&#x3D; 0，x0&#x3D; 2，y0 &#x3D; 2 带入上式， 令σ&#x3D; 1，得到约等于0.0175，这样得到</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114183327.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114183327.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="2"></p><p>通过取整变符号，且模板总和为0，得到下图所示的模板。</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114183403.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114183403.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>通常高斯分布中，在（-3σ，3σ）的范围内就覆盖了绝大部分区域，所以模板大小一般取dim &#x3D; 1 + 6σ（在SIFT 特征中，其中的高斯模糊也是这样取），dim 如果为小数，则取不小于dim 的最小整数，当然实际使用时没有这么严格，如上面我们取σ&#x3D;1 时，模板大小取5*5。那同一个尺寸的模板中的权值调整就是σ的变化得到的，变化到一定程度，模板尺寸大小改变。</p></blockquote><h3 id="Canny算子：非微分算子"><a href="#Canny算子：非微分算子" class="headerlink" title="Canny算子：非微分算子"></a>Canny算子：非微分算子</h3><h4 id="【基本原理】"><a href="#【基本原理】" class="headerlink" title="【基本原理】"></a>【<strong>基本原理</strong>】</h4><blockquote><ul><li>图象边缘检测必须满足两个条件:<ul><li>能有效的抑制噪声。</li><li>必须尽量精确确定边缘的位置。</li></ul></li><li>根据对信噪比与定位乘积进行测度，，得到最优化逼近算子。这就是Canny边缘检测算子。</li><li>类似与LoG边缘检测方法，也属于先平滑后求导数的方法。</li></ul></blockquote><h4 id="【算法步骤】"><a href="#【算法步骤】" class="headerlink" title="【算法步骤】"></a>【<strong>算法步骤</strong>】</h4><blockquote><ol><li>使用高斯滤波器，以平滑图像，滤除噪声。</li><li>计算图像中每个像素点的梯度强度和方向。</li><li>应用非极大值（Non-Maximum Suppression）抑制， 以消除边缘检测带着的杂散响应。</li><li>应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。</li><li>通过抑制孤立的弱边缘最终完成边缘检测。</li></ol></blockquote><h5 id="第一步：同时平滑与微分"><a href="#第一步：同时平滑与微分" class="headerlink" title="第一步：同时平滑与微分"></a>第一步：同时平滑与微分</h5><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114184750.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114184750.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><p>使用高斯函数的一阶导数同时完成平滑和微分。</p></blockquote><h5 id="第二步：计算梯度和方向"><a href="#第二步：计算梯度和方向" class="headerlink" title="第二步：计算梯度和方向"></a>第二步：计算梯度和方向</h5><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185109.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185109.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="2"></p><ul><li>梯度幅值和方向</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185153.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185153.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="2"></p><ul><li>方向离散化：离散化为上下左右和斜45°共4个方向</li></ul><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185232.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185232.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h5 id="第三步：梯度幅值非极大值抑制"><a href="#第三步：梯度幅值非极大值抑制" class="headerlink" title="第三步：梯度幅值非极大值抑制"></a>第三步：梯度幅值非极大值抑制</h5><p>细化梯度幅值图像中的屋脊带，只保留幅值局部变化最大的点</p><blockquote><p>使用一个3*3邻域作用于幅值阵列的所有点。在每一点上, 邻域的中心像素与沿梯度方向的两个梯度幅值的插值结果进行较，仅保留极大值点</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185542.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185542.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="3"></p><h5 id="第四步：边缘连接"><a href="#第四步：边缘连接" class="headerlink" title="第四步：边缘连接"></a>第四步：边缘连接</h5><p>对上一步得到的图像使用低、高阈值t1, t2 阈值化，得到三幅图像</p><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185713.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185713.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>T1对应假边缘，去除</li><li>T3对应真边缘，全部保留</li><li>T2连接：临接像素中是否有属于T3的像素</li></ul></blockquote><h5 id="第五步：抑制孤立低阈值点"><a href="#第五步：抑制孤立低阈值点" class="headerlink" title="第五步：抑制孤立低阈值点"></a>第五步：抑制孤立低阈值点</h5><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185951.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190114185951.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="5"></p><h3 id="边缘检测总结"><a href="#边缘检测总结" class="headerlink" title="边缘检测总结"></a>边缘检测总结</h3><blockquote><ol><li>边缘检测即图像差分</li><li>常见边缘检测算子包括Robert算子，Sobel算子，LoG算子等，其中Sobel算子最为常用</li><li>Canny算子的基本优点在于检测准确、对噪声稳健，在实际中广泛应用.</li></ol></blockquote><h3 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图片</span></span><br><span class="line">image = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>)</span><br><span class="line">img = cv2.pyrDown(image)</span><br><span class="line">cv2.imshow(<span class="string">&quot;source image&quot;</span>, img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RobertImage</span>(<span class="params">img, name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    robert算子的实现</span></span><br><span class="line"><span class="string">    :param img:</span></span><br><span class="line"><span class="string">    :param name:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    r_sunnzi = np.array([[-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]], np.float32)</span><br><span class="line">    robertImage = cv2.filter2D(img, -<span class="number">1</span>, r_sunnzi)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;Robert-%s&quot;</span> % name, robertImage)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sobelImage</span>(<span class="params">img, name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Sobel算子</span></span><br><span class="line"><span class="string">    Sobel(src, ddepth, dx, dy, dst=None, ksize=None, scale=None, delta=None, borderType=None)</span></span><br><span class="line"><span class="string">    前四个是必须的参数：</span></span><br><span class="line"><span class="string">    第一个参数是需要处理的图像；</span></span><br><span class="line"><span class="string">    第二个参数是图像的深度，-1表示采用的是与原图像相同的深度。目标图像的深度必须大于等于原图像的深度；</span></span><br><span class="line"><span class="string">    dx和dy表示的是求导的阶数，0表示这个方向上没有求导，一般为0、1、2。</span></span><br><span class="line"><span class="string">    其后是可选的参数：</span></span><br><span class="line"><span class="string">    dst不用解释了；</span></span><br><span class="line"><span class="string">    ksize是Sobel算子的大小，必须为1、3、5、7。</span></span><br><span class="line"><span class="string">    scale是缩放导数的比例常数，默认情况下没有伸缩系数；</span></span><br><span class="line"><span class="string">    delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中；</span></span><br><span class="line"><span class="string">    borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT。</span></span><br><span class="line"><span class="string">    :param img: 图片数据</span></span><br><span class="line"><span class="string">    :param name: 命名标志</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 先检测xy方向上的边缘</span></span><br><span class="line">    Sobel_Ex = cv2.Sobel(src=img, ddepth=cv2.CV_16S, dx=<span class="number">1</span>, dy=<span class="number">0</span>, ksize=<span class="number">3</span>)</span><br><span class="line">    Sobel_Ey = cv2.Sobel(src=img, ddepth=cv2.CV_16S, dx=<span class="number">0</span>, dy=<span class="number">1</span>, ksize=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 即Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，</span></span><br><span class="line">    <span class="comment"># 所以Sobel建立的图像位数不够，会有截断。因此要使用16位有符号的数据类型，即cv2.CV_16S。</span></span><br><span class="line">    <span class="comment"># cv2.imshow(&quot;Sobel_Ex-%s&quot; % name, Sobel_Ex)</span></span><br><span class="line">    <span class="comment"># 图像的每一个像素的横向及纵向梯度近似值结合</span></span><br><span class="line">    <span class="comment"># 用convertScaleAbs()函数将其转回原来的uint8形式。否则将无法显示图像，而只是一副灰色的窗口。</span></span><br><span class="line">    absX = cv2.convertScaleAbs(Sobel_Ex)</span><br><span class="line">    absY = cv2.convertScaleAbs(Sobel_Ey)</span><br><span class="line">    <span class="comment"># cv2.imshow(&quot;absX-%s&quot; % name, absX)</span></span><br><span class="line">    <span class="comment"># cv2.imshow(&quot;absY-%s&quot; % name, absY)</span></span><br><span class="line"></span><br><span class="line">    SobelImage = cv2.addWeighted(absX, <span class="number">0.5</span>, absY, <span class="number">0.5</span>, <span class="number">0</span>)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;sobel-%s&quot;</span> % name, SobelImage)</span><br><span class="line">    <span class="comment"># ddepth=-1表示图像深度和原图深度一致</span></span><br><span class="line">    <span class="comment"># Ex = cv2.Sobel(img, -1, 1, 0, ksize=3)</span></span><br><span class="line">    <span class="comment"># Ey = cv2.Sobel(img, -1, 0, 1, ksize=3)</span></span><br><span class="line">    <span class="comment"># # cv2.imshow(&quot;Ex-%s&quot; % name, Ex)</span></span><br><span class="line">    <span class="comment"># SobelImg = cv2.addWeighted(Ex, 0.5, Ey, 0.5, 0)</span></span><br><span class="line">    <span class="comment"># cv2.imshow(&quot;soImg-%s&quot; % name, SobelImg)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">LaplaceImage</span>(<span class="params">img, name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Laplace算子</span></span><br><span class="line"><span class="string">    Laplacian(src, ddepth, dst=None, ksize=None, scale=None, delta=None, borderType=None)</span></span><br><span class="line"><span class="string">    前两个是必须的参数：</span></span><br><span class="line"><span class="string">    第一个参数是需要处理的图像；</span></span><br><span class="line"><span class="string">    第二个参数是图像的深度，-1表示采用的是与原图像相同的深度。目标图像的深度必须大于等于原图像的深度；</span></span><br><span class="line"><span class="string">    其后是可选的参数：</span></span><br><span class="line"><span class="string">    dst不用解释了；</span></span><br><span class="line"><span class="string">    ksize是算子的大小，必须为1、3、5、7。默认为1。</span></span><br><span class="line"><span class="string">    scale是缩放导数的比例常数，默认情况下没有伸缩系数；</span></span><br><span class="line"><span class="string">    delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中；</span></span><br><span class="line"><span class="string">    borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT。</span></span><br><span class="line"><span class="string">    :param img: 图片数据</span></span><br><span class="line"><span class="string">    :param name: 命名标志</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># ddepth=-1表示图像深度和原图深度一致</span></span><br><span class="line">    <span class="comment"># laplaceImage = cv2.Laplacian(img, ddepth=-1, ksize=3)</span></span><br><span class="line">    <span class="comment"># cv2.imshow(&quot;laplace-%s&quot; % name, laplaceImage)</span></span><br><span class="line">    <span class="comment"># ddepth=cv2.CV_16S表示图像深度</span></span><br><span class="line">    laplaceImg = cv2.Laplacian(img, ddepth=cv2.CV_16S, ksize=<span class="number">3</span>)</span><br><span class="line">    lapimg = cv2.convertScaleAbs(laplaceImg)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;laplace-%s&quot;</span> % name, lapimg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">LoG</span>(<span class="params">img, name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    LoG算子的实现</span></span><br><span class="line"><span class="string">    :param img:</span></span><br><span class="line"><span class="string">    :param name:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    gaussImage = cv2.GaussianBlur(img, (<span class="number">5</span>, <span class="number">5</span>), <span class="number">0.01</span>)</span><br><span class="line">    laplaceImg = cv2.Laplacian(gaussImage, ddepth=cv2.CV_16S, ksize=<span class="number">3</span>)</span><br><span class="line">    logImg = cv2.convertScaleAbs(laplaceImg)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;LoG-%s&quot;</span> % name, logImg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">CannyImage</span>(<span class="params">img, name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    必要参数：</span></span><br><span class="line"><span class="string">    第一个参数是需要处理的原图像，该图像必须为单通道的灰度图；</span></span><br><span class="line"><span class="string">    第二个参数是阈值1；</span></span><br><span class="line"><span class="string">    第三个参数是阈值2。</span></span><br><span class="line"><span class="string">    其中较大的阈值2用于检测图像中明显的边缘，但一般情况下检测的效果不会那么完美，</span></span><br><span class="line"><span class="string">    边缘检测出来是断断续续的。所以这时候用较小的第一个阈值用于将这些间断的边缘连接起来。</span></span><br><span class="line"><span class="string">    :param img: 图片数据</span></span><br><span class="line"><span class="string">    :param name: 命名标志</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 先进行高斯平滑</span></span><br><span class="line">    gaussImage = cv2.GaussianBlur(img, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 边缘检测，最大阈值为150，最小阈值为50</span></span><br><span class="line">    <span class="comment"># Canny 推荐的 高:低 阈值比在 2:1 到3:1之间。</span></span><br><span class="line">    cannyImage = cv2.Canny(gaussImage, <span class="number">50</span>, <span class="number">150</span>)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;canny-%s&quot;</span> % name, cannyImage)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 彩色图像进行Robert边缘检测</span></span><br><span class="line">RobertImage(img, <span class="string">&#x27;rgb&#x27;</span>)</span><br><span class="line"><span class="comment"># 灰度图像进行robert边缘检测</span></span><br><span class="line">grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">RobertImage(grayImage, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 彩色图像进行sobel边缘检测</span></span><br><span class="line">sobelImage(img, <span class="string">&#x27;rgb&#x27;</span>)</span><br><span class="line"><span class="comment"># 灰度图像进行sobel边缘检测</span></span><br><span class="line">grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">sobelImage(grayImage, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 彩色图像进行laplace边缘检测</span></span><br><span class="line">LaplaceImage(img, <span class="string">&#x27;rgb&#x27;</span>)</span><br><span class="line"><span class="comment"># 灰度图像进行laplace边缘检测</span></span><br><span class="line">grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">LaplaceImage(grayImage, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 彩色图像进行LoG边缘检测</span></span><br><span class="line">LoG(img, <span class="string">&#x27;rgb&#x27;</span>)</span><br><span class="line"><span class="comment"># 灰度图像进行LoG边缘检测</span></span><br><span class="line">grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">LoG(grayImage, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 彩色图像进行canny边缘检测</span></span><br><span class="line">CannyImage(img, <span class="string">&#x27;rgb&#x27;</span>)</span><br><span class="line"><span class="comment"># 灰度图像进行canny边缘检测</span></span><br><span class="line">grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">CannyImage(grayImage, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190115192824.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190115192824.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="代码演示"></p><blockquote><ul><li>sobel 产生的边缘有强弱，抗噪性好</li><li>laplace 对边缘敏感，可能有些是噪声的边缘，也被算进来了</li><li>canny 产生的边缘很细，可能就一个像素那么细，没有强弱之分。</li></ul></blockquote>]]></content>
    
    
    <summary type="html">视觉处理算-图像边缘检测</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>【六】直方图</title>
    <link href="https://aicc-cn.github.io/2019/03/22/2019-03-06-cv-image_hist/"/>
    <id>https://aicc-cn.github.io/2019/03/22/2019-03-06-cv-image_hist/</id>
    <published>2019-03-21T16:00:00.000Z</published>
    <updated>2022-03-30T13:09:04.127Z</updated>
    
    <content type="html"><![CDATA[<h3 id="图像直方图"><a href="#图像直方图" class="headerlink" title="图像直方图"></a><strong>图像直方图</strong></h3><blockquote><p>通过灰度直方图看到图像的照明效果</p></blockquote><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190115154350.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190115154350.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="![](https://eveseven.oss-cn-shanghai.aliyuncs.com/20190115154324.png)"></p><h3 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2019/3/9 21:28</span></span><br><span class="line"><span class="comment"># @Author  : Seven</span></span><br><span class="line"><span class="comment"># @File    : HistDemo.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># function : 图像直方图</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GrayHist</span>(<span class="params">img</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    calcHist(images, channels, mask, histSize, ranges, hist=None, accumulate=None)</span></span><br><span class="line"><span class="string">    images — 源矩阵指针（输入图像，可以多张）。 但都应当有同样的深度（depth）, 比如CV_8U 或者 CV_32F ，</span></span><br><span class="line"><span class="string">             和同样的大小。每张图片可以拥有任意数量的通道。</span></span><br><span class="line"><span class="string">    channels — 通道的数量，每个通道都有编号，灰度图为一通道，即channel[1]=0;对应着一维。</span></span><br><span class="line"><span class="string">                BGR三通道图像编号为channels[3]=&#123;0,1,2&#125;;分别对应着第一维，第二维，第三维。</span></span><br><span class="line"><span class="string">    mask — 掩码图像：要对图像处理时，先看看这个像素对应的掩码位是否为屏蔽，如果为屏蔽，就是说该像素不处理（掩码值为0的像素都将被忽略）</span></span><br><span class="line"><span class="string">    hist — 返回的直方图。</span></span><br><span class="line"><span class="string">    histSize — 直方图每一维的条目个数的数组，灰度图一维有256个条目。</span></span><br><span class="line"><span class="string">    ranges — 每一维的像素值的范围，传递数组，与维数相对应，灰度图一维像素值范围为0~255。</span></span><br><span class="line"><span class="string">    :param name: 命名标志</span></span><br><span class="line"><span class="string">    :param img: 图片数据</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    hist = cv2.calcHist([img],</span><br><span class="line">                            [<span class="number">0</span>],</span><br><span class="line">                            <span class="literal">None</span>,</span><br><span class="line">                            [<span class="number">256</span>],</span><br><span class="line">                            [<span class="number">0.0</span>, <span class="number">255.0</span>])</span><br><span class="line"></span><br><span class="line">    plt.plot(hist)</span><br><span class="line">    plt.xlim([<span class="number">0</span>, <span class="number">256</span>])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">colorHist</span>(<span class="params">img</span>):</span><br><span class="line">    <span class="comment"># 颜色直方图</span></span><br><span class="line">    channels = cv2.split(img)</span><br><span class="line"></span><br><span class="line">    colors = (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> (chan, color) <span class="keyword">in</span> <span class="built_in">zip</span>(channels, colors):</span><br><span class="line">        hist = cv2.calcHist([chan], [<span class="number">0</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">256</span>])</span><br><span class="line">        plt.plot(hist, color=color)</span><br><span class="line">        plt.xlim([<span class="number">0</span>, <span class="number">256</span>])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">channelsHist</span>(<span class="params">img</span>):</span><br><span class="line">    b, g, r = cv2.split(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calcAndDrawHist</span>(<span class="params">image, color</span>):</span><br><span class="line">        hist = cv2.calcHist([image], [<span class="number">0</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0.0</span>, <span class="number">255.0</span>])</span><br><span class="line">        minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(hist)</span><br><span class="line">        histImg = np.zeros([<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>], np.uint8)</span><br><span class="line">        hpt = <span class="built_in">int</span>(<span class="number">0.9</span> * <span class="number">256</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">256</span>):</span><br><span class="line">            intensity = <span class="built_in">int</span>(hist[h] * hpt / maxVal)</span><br><span class="line">            cv2.line(histImg, (h, <span class="number">256</span>), (h, <span class="number">256</span> - intensity), color)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> histImg;</span><br><span class="line"></span><br><span class="line">    histImgB = calcAndDrawHist(b, [<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">    histImgG = calcAndDrawHist(g, [<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>])</span><br><span class="line">    histImgR = calcAndDrawHist(r, [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>])</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    plt.subplot(<span class="number">221</span>)</span><br><span class="line">    plt.imshow(img[:, :, ::-<span class="number">1</span>]);</span><br><span class="line">    plt.title(<span class="string">&#x27;origin&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">222</span>)</span><br><span class="line">    plt.imshow(histImgB[:, :, ::-<span class="number">1</span>]);</span><br><span class="line">    plt.title(<span class="string">&#x27;histImgB&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">223</span>)</span><br><span class="line">    plt.imshow(histImgG[:, :, ::-<span class="number">1</span>]);</span><br><span class="line">    plt.title(<span class="string">&#x27;histImgG&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">224</span>)</span><br><span class="line">    plt.imshow(histImgR[:, :, ::-<span class="number">1</span>]);</span><br><span class="line">    plt.title(<span class="string">&#x27;histImgR&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">grayEqualize</span>(<span class="params">img</span>):</span><br><span class="line">    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    equ = cv2.equalizeHist(img)</span><br><span class="line">    <span class="comment"># 两个图片的像素分布连接在一起，拍成一维数组</span></span><br><span class="line">    res = np.hstack((img, equ))</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    ax1 = plt.subplot2grid((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    ax1.imshow(img, cmap=plt.cm.gray)</span><br><span class="line">    ax1.set_title(<span class="string">&#x27;orignal image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    ax1 = plt.subplot2grid((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    ax1.imshow(equ, cmap=plt.cm.gray)</span><br><span class="line">    ax1.set_title(<span class="string">&#x27;equalization&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    ax1 = plt.subplot2grid((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">0</span>), colspan=<span class="number">3</span>, rowspan=<span class="number">1</span>)</span><br><span class="line">    ax1.imshow(res, cmap=plt.cm.gray)</span><br><span class="line">    ax1.set_title(<span class="string">&#x27;horizational&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">colorEqualize</span>(<span class="params">img</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hisEqulColor</span>(<span class="params">img</span>):</span><br><span class="line">        ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)</span><br><span class="line">        channels = cv2.split(ycrcb)</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(channels))</span><br><span class="line">        cv2.equalizeHist(channels[<span class="number">0</span>], channels[<span class="number">0</span>])</span><br><span class="line">        cv2.merge(channels, ycrcb)</span><br><span class="line">        cv2.cvtColor(ycrcb, cv2.COLOR_YCR_CB2BGR, img)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    equ = hisEqulColor(img)</span><br><span class="line"></span><br><span class="line">    h_stack_img = np.hstack((img, equ))</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">    ax1 = plt.subplot2grid((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    ax1.imshow(img[:, :, ::-<span class="number">1</span>])</span><br><span class="line">    ax1.set_title(<span class="string">&#x27;orignal image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    ax1 = plt.subplot2grid((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    ax1.imshow(equ[:, :, ::-<span class="number">1</span>])</span><br><span class="line">    ax1.set_title(<span class="string">&#x27;equalization&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    ax1 = plt.subplot2grid((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">0</span>), colspan=<span class="number">3</span>, rowspan=<span class="number">1</span>)</span><br><span class="line">    ax1.imshow(h_stack_img[:, :, ::-<span class="number">1</span>])</span><br><span class="line">    ax1.set_title(<span class="string">&#x27;horizational&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.title(<span class="string">&quot;Grayscale Histogram&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Bins&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;# of Pixels&quot;</span>)</span><br><span class="line"><span class="comment"># 灰度直方图</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;lena.jpg&#x27;</span>)</span><br><span class="line">GrayHist(img)</span><br><span class="line"><span class="comment"># 颜色直方图</span></span><br><span class="line">colorHist(img)</span><br><span class="line"><span class="comment"># 多通道直方图</span></span><br><span class="line">channelsHist(img)</span><br><span class="line"><span class="comment"># 灰度直方图均衡</span></span><br><span class="line">grayEqualize(img)</span><br><span class="line"><span class="comment"># 彩色图像直方图均衡</span></span><br><span class="line">colorEqualize(img)</span><br></pre></td></tr></table></figure><h4 id="灰度直方图"><a href="#灰度直方图" class="headerlink" title="灰度直方图"></a>灰度直方图</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322210855.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322210855.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="颜色直方图"><a href="#颜色直方图" class="headerlink" title="颜色直方图"></a>颜色直方图</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322210923.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322210923.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="多通道直方图"><a href="#多通道直方图" class="headerlink" title="多通道直方图"></a>多通道直方图</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322210948.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322210948.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="灰度直方图均衡"><a href="#灰度直方图均衡" class="headerlink" title="灰度直方图均衡"></a>灰度直方图均衡</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322211034.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322211034.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="彩色图像直方图均衡"><a href="#彩色图像直方图均衡" class="headerlink" title="彩色图像直方图均衡"></a>彩色图像直方图均衡</h4><p><img src="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322211109.png" class="lazyload" data-srcset="https://eveseven.oss-cn-shanghai.aliyuncs.com/20190322211109.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>]]></content>
    
    
    <summary type="html">视觉处理算-直方图</summary>
    
    
    
    <category term="机器视觉" scheme="https://aicc-cn.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="OpenCV" scheme="https://aicc-cn.github.io/tags/OpenCV/"/>
    
  </entry>
  
</feed>
